{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twin Neural Network for analyzing diffraction images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import socket\n",
    "print(socket.gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import h5py\n",
    "#import pydot\n",
    "import graphviz\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle2idx = {\n",
    "    '1fpv': 0,\n",
    "    '1ss8': 1,\n",
    "    '3j03': 2,\n",
    "    '1ijg': 3,\n",
    "    '3iyf': 4,\n",
    "    '6ody': 5,\n",
    "    '6sp2': 6,\n",
    "    '6xs6': 7,\n",
    "    '7dwz': 8,\n",
    "    '7dx8': 9,\n",
    "    '7dx9': 10\n",
    "}\n",
    "\n",
    "count2idx = {\n",
    "    'single': 0,\n",
    "    'double': 1,\n",
    "    'triple': 2,\n",
    "    'quadruple': 3\n",
    "}\n",
    "\n",
    "hit2idx = {\n",
    "    'single_hit': 0,\n",
    "    'multi_hit': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2particle = {\n",
    "    0: '1fpv',\n",
    "    1: '1ss8',\n",
    "    2: '3j03',\n",
    "    3: '1ijg',\n",
    "    4: '3iyf',\n",
    "    5: '6ody',\n",
    "    6: '6sp2',\n",
    "    7: '6xs6',\n",
    "    8: '7dwz',\n",
    "    9: '7dx8',\n",
    "    10: '7dx9'\n",
    "}\n",
    "\n",
    "idx2count = {\n",
    "    0: 'single',\n",
    "    1: 'double',\n",
    "    2: 'triple',\n",
    "    3: 'quadruple'\n",
    "}\n",
    "\n",
    "idx2hit = {\n",
    "    0: 'single_hit',\n",
    "    1: 'multi_hit'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNoise(orig_img, flux_jitter=0.9, gaussian_noise=0.15):\n",
    "    \n",
    "    \"\"\"\n",
    "    Adds augmentations and noise to batches of diffraction images.\n",
    "    \n",
    "    The following augmentations are applied to images:\n",
    "    1. Random rotation between (-360, 360).\n",
    "    2. Random vertical and horizontal flips.\n",
    "    3. Random zoom-in and zoom-out between (0.9x, 1.1x)\n",
    "    \n",
    "    The following noise are applied to images:\n",
    "    1. Reduce the fluence by a factor of 100.\n",
    "    2. Add poisson noise.\n",
    "    3. Add gaussian noise given a sigma value.\n",
    "    4. Varience normalization.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    orig_img: list(numpy.array)\n",
    "        Batch of diffraction images represented by numpy.array\n",
    "    flux_jitter: float\n",
    "        Flux jitter to include when reducing fluence of images.\n",
    "    gaussian_noise: float\n",
    "        Alias for sigma used in gaussian distribution; specifies how much gaussian noise to include in the images.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    Batch of transformed images from orig_img.\n",
    "    \"\"\"\n",
    "\n",
    "    def changeIntensity(img, flux_jitter):\n",
    "        factor = 100 # Reduces the fluence of the image by a factor of 100. Ex. 1e14 photons/pulse -> 1e12 photons/pulse.\n",
    "        mu = 1 # mean jitter\n",
    "        alpha = np.random.normal(mu, flux_jitter)\n",
    "        if alpha <= 0: alpha = 0.1 # alpha can't be zero\n",
    "        n_photons = alpha*np.sum(img) / factor                     # number of desired photons per image\n",
    "        return n_photons*(img/np.sum(img)) # cache noise-free measurement\n",
    "    \n",
    "    def poisson(img):\n",
    "        # add poisson noise\n",
    "        return np.random.poisson(img)      # apply Poisson statistics\n",
    "    \n",
    "    def gaussian(img, sigma):\n",
    "        # add gaussian noise \n",
    "        # For random samples from N(\\mu, \\sigma^2), \n",
    "        # mu + sigma * np.random.randn(...)\n",
    "        # sigma: Gaussian noise level\n",
    "        img = img + sigma*np.random.randn(*img.shape);  # apply Gaussian statistics\n",
    "        return img\n",
    "    \n",
    "    def varNorm(V):\n",
    "        # variance normalization, each image has mean 0, variance 1\n",
    "        # This shouldn't happen, but zero out infinite pixels\n",
    "        V[np.argwhere(V==np.inf)] = 0\n",
    "        mean = np.mean(V)\n",
    "        std = np.std(V)\n",
    "        if std == 0:\n",
    "            return np.zeros_like(V)\n",
    "        V1 = (V-mean)/std\n",
    "        return V1\n",
    "    \n",
    "    def rotation_transform(img, rotation_range):\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        img = tf.keras.preprocessing.image.random_rotation(x=img, rg=rotation_range, row_axis=0, col_axis=1, channel_axis=2,\n",
    "                                                           fill_mode='constant', cval=0.0)\n",
    "        img = np.squeeze(img)\n",
    "        return img\n",
    "    \n",
    "    def vertical_flip_transform(img):\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        img = tf.image.random_flip_left_right(img).numpy()\n",
    "        img = np.squeeze(img)\n",
    "        return img\n",
    "    \n",
    "    def horizontal_flip_transform(img):\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        img = tf.image.random_flip_up_down(img).numpy()\n",
    "        img = np.squeeze(img)\n",
    "        return img\n",
    "    \n",
    "    def zoom_transform(img, zoom_range):\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        img = tf.keras.preprocessing.image.random_zoom(x=img, zoom_range=zoom_range, row_axis=0, col_axis=1, channel_axis=2,\n",
    "                                                       fill_mode='constant', cval=0.0)\n",
    "        img = np.squeeze(img)\n",
    "        return img\n",
    "\n",
    "    def transform(img):\n",
    "        # Apply rotation, flips, and zooms before other noise.\n",
    "        img = rotation_transform(img, rotation_range=360)\n",
    "        img = vertical_flip_transform(img)\n",
    "        img = horizontal_flip_transform(img)\n",
    "        img = zoom_transform(img, zoom_range=(0.9, 1.1))\n",
    "        \n",
    "        img = changeIntensity(img, flux_jitter)\n",
    "        img = poisson(img)\n",
    "        img = gaussian(img, gaussian_noise)\n",
    "        img = varNorm(img)\n",
    "        return img\n",
    "    \n",
    "    # \"orig_img\" is actually a \"mini-batch\" of images.\n",
    "    # This loops applies the transforms to every image in that \"mini-batch\"\n",
    "    for i in range(orig_img.shape[0]):\n",
    "        orig_img[i] = transform(img=orig_img[i])\n",
    "    \n",
    "    return orig_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loads data and label them by count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(num_train_samples=200, num_test_samples=50, normalize=None, seed=None):\n",
    "    \"\"\"\n",
    "    Loads the data that will be used for model training. Labels diffraction images\n",
    "    by their respective particle count.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_train_samples: int\n",
    "        Number of training samples to include in training dataset.\n",
    "    num_test_samples: int\n",
    "        Number of test samples to include in test dataset.\n",
    "    normalize: str\n",
    "        Type of intensity normalization.\n",
    "        Pick from the following: {'variance'}\n",
    "    seed: int\n",
    "        Seed used to randomly split the data.\n",
    "            \n",
    "    Return\n",
    "    ------\n",
    "    (x_train, y_train): List of diffraction images and their labels, with a size of num_train_samples.\n",
    "\n",
    "    (x_test, y_test): List of diffraction images and their labels, with a size of num_test_samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    # num_train_sample must be divisible by 2\n",
    "    # TODO: Change path to proper location.\n",
    "    path = '/scratch/xericfl/eric_data/'\n",
    "    \n",
    "    # Filenames for datasets containing diffraction image thumbnails.\n",
    "    fnames = ['1fpv_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '6sp2_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '1ijg_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '6xs6_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '1ss8_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '7dwz_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '3iyf_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '7dx8_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '3j03_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '7dx9_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '6ody_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '1fpv_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '6sp2_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '1ijg_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '6xs6_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '1ss8_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '7dwz_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '3iyf_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '7dx8_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '3j03_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '7dx9_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '6ody_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '1fpv_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '6sp2_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '1ijg_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '6xs6_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '1ss8_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '7dwz_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '3iyf_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '7dx8_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '3j03_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '7dx9_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '6ody_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '1fpv_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '6sp2_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '1ijg_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '6xs6_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '1ss8_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '7dwz_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '3iyf_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '7dx8_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '3j03_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '7dx9_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '6ody_5k_quadruple_pps_1e14_thumbnail.h5']\n",
    "    \n",
    "    # Number of files to go through.\n",
    "    numFiles = len(fnames)\n",
    "    \n",
    "    # Initialize numpy random number generator.\n",
    "    if seed is not None: \n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Get image dimensions\n",
    "    with h5py.File(path+fnames[0],'r') as f:\n",
    "        img = f['photons'][0,:,:]\n",
    "        nR,nC = img.shape\n",
    "            \n",
    "    # TRAIN\n",
    "    x_train = np.empty((num_train_samples, nR, nC), dtype='float32')\n",
    "    y_train = np.empty((num_train_samples,), dtype='uint8')\n",
    "    index = np.random.randint(0, numFiles, num_train_samples)\n",
    "    for i, fname in enumerate(fnames):\n",
    "        ind = np.where(index == i)[0]\n",
    "        if len(ind) > 0:\n",
    "            with h5py.File(path+fname,'r') as f:\n",
    "                \n",
    "                # Apply augmentations and noise to image.\n",
    "                x_train[ind] = addNoise(f['photons'][0:len(ind),:,:], flux_jitter=0.9, gaussian_noise=0.15)\n",
    "                print(fname, len(ind))\n",
    "                \n",
    "                # Set particle count label\n",
    "                if 'single' in fname:\n",
    "                    y_train[ind] = hit2idx['single_hit']\n",
    "                elif ('double' in fname) or ('triple' in fname) or ('quadruple' in fname):\n",
    "                    y_train[ind] = hit2idx['multi_hit']\n",
    "                else:\n",
    "                    raise Exception('Unknown file being processed. Be sure that one of the following count types are in the file name: \\\"single\\\", \\\"double\\\", \\\"triple\\\", or \\\"quadruple\\\"')\n",
    "\n",
    "\n",
    "    # TEST\n",
    "    x_test = np.empty((num_test_samples, nR, nC), dtype='float32')\n",
    "    y_test = np.empty((num_test_samples,), dtype='uint8')\n",
    "    index = np.random.randint(0,numFiles,num_test_samples)\n",
    "    for i, fname in enumerate(fnames):\n",
    "        ind = np.where(index == i)[0] \n",
    "        if len(ind) > 0:\n",
    "            with h5py.File(path+fname,'r') as f:\n",
    "                # apply offset since first num_train_samples have been used\n",
    "                offset = round(num_train_samples/numFiles)\n",
    "                \n",
    "                # Apply augmentations and noise to image.\n",
    "                x_test[ind] = addNoise(f['photons'][offset:len(ind)+offset,:,:], flux_jitter=0.9, gaussian_noise=0.15)\n",
    "                \n",
    "                # Set particle count label.\n",
    "                if 'single' in fname:\n",
    "                    y_test[ind] = hit2idx['single_hit']\n",
    "                elif ('double' in fname) or ('triple' in fname) or ('quadruple' in fname):\n",
    "                    y_test[ind] = hit2idx['multi_hit']\n",
    "                else:\n",
    "                    raise Exception('Unknown file being processed. Be sure that one of the following count types are in the file name: \\\"single\\\", \\\"double\\\", \\\"triple\\\", or \\\"quadruple\\\"')\n",
    "\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "(x_train, y_train), (x_test, y_test) = load_data(num_train_samples=200, num_test_samples=50, normalize=None, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize dataset\n",
    "print(x_train.shape)\n",
    "(num_train, dim_r, dim_c) = x_train.shape\n",
    "num_test = x_test.shape[0]\n",
    "img_dim = dim_r * dim_c\n",
    "\n",
    "x_train = np.reshape(x_train, (num_train, img_dim)) # reshape to vectors\n",
    "x_test = np.reshape(x_test, (num_test, img_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting triplet (anchor, positive, negative)\n",
    "def plot_triplet(triplet, labels):\n",
    "    plt.figure(figsize=(6,2))\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.imshow(np.reshape(triplet[i], (dim_r, dim_c)), cmap='binary')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "           \n",
    "        if i == 0: plt.title('anchor: {}'.format(idx2hit[labels[i].item()]))\n",
    "        if i == 1: plt.title('positive: {}'.format(idx2hit[labels[i].item()]))\n",
    "        if i == 2: plt.title('negative: {}'.format(idx2hit[labels[i].item()]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a batch of triplets\n",
    "def create_batch(batch_size, anchor_label=None):\n",
    "    \n",
    "    # Holds diffraction images for the anchor, positive, and negative triplets.\n",
    "    anchors = np.zeros((batch_size, img_dim))\n",
    "    positives = np.zeros((batch_size, img_dim))\n",
    "    negatives = np.zeros((batch_size, img_dim))\n",
    "    \n",
    "    # Holds labels, where [ind, 0] contains PDB ID and [ind, 1] contains count classification.\n",
    "    anchor_labels = np.zeros((batch_size,), dtype=int)\n",
    "    positive_labels = np.zeros((batch_size,), dtype=int)\n",
    "    negative_labels = np.zeros((batch_size,), dtype=int)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        # Pick an anchor that matches anchor_label if given\n",
    "        if anchor_label is not None:\n",
    "            indices_for_anc = np.squeeze(np.where(y_train == anchor_label))\n",
    "            index = indices_for_anc[np.random.randint(0, len(indices_for_anc)-1)]\n",
    "        else:\n",
    "            index = np.random.randint(0, num_train-1)\n",
    "        \n",
    "        # Retrieve anchor image and it's label from the given index.\n",
    "        anc = x_train[index]\n",
    "        y = y_train[index]\n",
    "        \n",
    "        # Get indices for positive and negative images to create triplet pairs.\n",
    "        indices_for_pos = np.squeeze(np.where(y_train == y))\n",
    "        indices_for_neg = np.squeeze(np.where(y_train != y))\n",
    "        \n",
    "        # Get a random positive image index and negative image index.\n",
    "        pos_idx = indices_for_pos[np.random.randint(0, len(indices_for_pos)-1)]\n",
    "        neg_idx = indices_for_neg[np.random.randint(0, len(indices_for_neg)-1)]\n",
    "        \n",
    "        # Retrieve positive and negative images from the given pos_idx and neg_idx indices.\n",
    "        pos = x_train[pos_idx]\n",
    "        neg = x_train[neg_idx]\n",
    "        \n",
    "        # Assign anchor, positive, and negative.\n",
    "        anchors[i] = anc\n",
    "        positives[i] = pos\n",
    "        negatives[i] = neg\n",
    "        \n",
    "        # Assign anchor, positive, and negative labels.\n",
    "        anchor_labels[i] = y\n",
    "        positive_labels[i] = y_train[pos_idx]\n",
    "        negative_labels[i] = y_train[neg_idx]\n",
    "        \n",
    "    # Returns image batches and (anc, pos, neg) labels\n",
    "    return [anchors, positives, negatives], [anchor_labels, positive_labels, negative_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a batch of triplet\n",
    "triplet, labels = create_batch(batch_size=1, anchor_label=0)\n",
    "plot_triplet(triplet, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the embedding model\n",
    "```emb_dim``` defines how many features the embedding model will extra from the diffraction images.\n",
    "\n",
    "```embedding_model``` defines the model used to create the embedding vectors from diffraction images. This could be a shallow network to a deep network, but the output is always an embedding vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model (2 dense layers w/ relu and sigmoid activation)\n",
    "\n",
    "# Experiment with this value.\n",
    "emb_dim = 4\n",
    "\n",
    "# Dense implements the operation: output = activation(dot(input, kernel) + bias)\n",
    "\n",
    "# Experiment with the embedding model's architecture.\n",
    "embedding_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(emb_dim, activation='relu', input_shape=(img_dim,)),\n",
    "    tf.keras.layers.Dense(emb_dim, activation='sigmoid')\n",
    "])\n",
    "\n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prints out an example embedding created by a diffraction image using the\n",
    "# embedding model.\n",
    "example = x_train[0]\n",
    "example_emb = embedding_model.predict(np.expand_dims(example, axis=0))\n",
    "print(\"example embedding: \", example_emb, example_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the example embedding.\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(example_emb[0],'x-'); plt.xlabel(\"features\"); plt.ylabel(\"weight\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the entire network\n",
    "Here we define the entire twin neural network that we will be using. This includes setting up the Input layers, the embedding model layer, and the output layer.\n",
    "\n",
    "The three inputs are an anchor diffraction image, a positive diffraction image, and a negative diffraction image. The output is a $1\\times(3*\\textrm{emb_dim})$ vector.\n",
    "1. $[0, \\textrm{emb_dim})$ contains the embedding weights of the anchor image.\n",
    "2. $[\\textrm{emb_dim}, 2*\\textrm{emb_dim})$ contains the embedding weights of the positive image.\n",
    "3. $[2*\\textrm{emb_dim}, 3*\\textrm{emb_dim})$ contains the embedding weights of the negative image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese network\n",
    "in_anc = tf.keras.layers.Input(shape=(img_dim,))\n",
    "in_pos = tf.keras.layers.Input(shape=(img_dim,))\n",
    "in_neg = tf.keras.layers.Input(shape=(img_dim,))\n",
    "\n",
    "em_anc = embedding_model(in_anc)\n",
    "em_pos = embedding_model(in_pos)\n",
    "em_neg = embedding_model(in_neg)\n",
    "\n",
    "out = tf.keras.layers.concatenate([em_anc, em_pos, em_neg], axis=1)\n",
    "\n",
    "net = tf.keras.models.Model(\n",
    "    [in_anc, in_pos, in_neg],\n",
    "    out\n",
    ")\n",
    "\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Loss\n",
    "A loss function that tries to pull the Embeddings of Anchor and Positive Examples closer, and tries to push the Embeddings of Anchor and Negative Examples away from each other.\n",
    "\n",
    "Root mean square difference between Anchor and Positive examples in a batch of N images is:\n",
    "$\n",
    "\\begin{equation}\n",
    "d_p = \\sqrt{\\frac{\\sum_{i=0}^{N-1}(f(a_i) - f(p_i))^2}{N}}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "Root mean square difference between Anchor and Negative examples in a batch of N images is:\n",
    "$\n",
    "\\begin{equation}\n",
    "d_n = \\sqrt{\\frac{\\sum_{i=0}^{N-1}(f(a_i) - f(n_i))^2}{N}}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "For each example, we want:\n",
    "$\n",
    "\\begin{equation}\n",
    "d_p \\leq d_n\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "Therefore,\n",
    "$\n",
    "\\begin{equation}\n",
    "d_p - d_n \\leq 0\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "This condition is quite easily satisfied during the training.\n",
    "\n",
    "We will make it non-trivial by adding a margin (alpha):\n",
    "$\n",
    "\\begin{equation}\n",
    "d_p - d_n + \\alpha \\leq 0\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "Given the condition above, the Triplet Loss L is defined as:\n",
    "$\n",
    "\\begin{equation}\n",
    "L = max(d_p - d_n + \\alpha, 0)\n",
    "\\end{equation}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(alpha, emb_dim):\n",
    "    \"\"\"\n",
    "    Triplet Loss function used in training the model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha: float\n",
    "        The alpha margin used in the comparison of anchor-positive distances and anchor-negative distances.\n",
    "    emb_dim: int\n",
    "        The size of the embedding vectors.\n",
    "    \"\"\"\n",
    "    def loss(y_true, y_pred):\n",
    "        anc, pos, neg = y_pred[:, :emb_dim], y_pred[:, emb_dim:2*emb_dim], y_pred[:, 2*emb_dim:]\n",
    "        dp = tf.reduce_mean(tf.square(anc - pos), axis=1)\n",
    "        dn = tf.reduce_mean(tf.square(anc - neg), axis=1)\n",
    "        return tf.maximum(dp - dn + alpha, 0.)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAPlotter(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    A class that plots the embedding space and loss of the twin neural network\n",
    "    during the training process.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, plt, embedding_model, x_test, y_test):\n",
    "        \"\"\"\n",
    "        Initialize PCAPlotter object.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        plt: matplotlib.pyplot\n",
    "            matplotlib object to plot embedding space and loss graph figures.\n",
    "        embedding_model: TensorFlow model\n",
    "            Embedding model used in the twin neural network.\n",
    "        x_test: numpy.array\n",
    "            Numpy array containing diffraction images used for testing the model in a training step.\n",
    "        y_test: numpy.array\n",
    "            Numpy array containing the labels of the diffraction images used for testing the model in a training step.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(PCAPlotter, self).__init__()\n",
    "        self.embedding_model = embedding_model\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.fig = plt.figure(figsize=(10, 10))\n",
    "        self.ax1 = plt.subplot(1, 2, 1)\n",
    "        self.ax2 = plt.subplot(1, 2, 2)\n",
    "        plt.ion()\n",
    "        \n",
    "        self.losses = []\n",
    "    \n",
    "    def plot(self, epoch=None, plot_loss=False):\n",
    "        \"\"\"\n",
    "        Plots the embedding space and model training loss plots.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        epoch: int\n",
    "            Current epoch model is on in training.\n",
    "        plot_loss: bool\n",
    "            If True, plot the training loss.\n",
    "            If False, does not plot the training loss.\n",
    "        \"\"\"\n",
    "        x_test_embeddings = self.embedding_model.predict(self.x_test)\n",
    "        pca_out = PCA(n_components=2).fit_transform(x_test_embeddings)\n",
    "        self.ax1.clear()\n",
    "        self.ax1.scatter(pca_out[:, 0], pca_out[:, 1], c=self.y_test, cmap='seismic')\n",
    "        if plot_loss:\n",
    "            self.ax2.clear()\n",
    "            self.ax2.plot(range(epoch), self.losses)\n",
    "            self.ax2.set_xlabel('Epochs')\n",
    "            self.ax2.set_ylabel('Loss')\n",
    "            self.ax2.set_title('Loss vs Epochs')\n",
    "        self.ax1.set_title('PCA embedding of Siamese embedding')\n",
    "        self.ax1.set_xlabel('principal component 1')\n",
    "        self.ax1.set_ylabel('principal component 2')\n",
    "        self.fig.canvas.draw()\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        \"\"\"\n",
    "        Executed when model training begins.\n",
    "        \n",
    "        Here:\n",
    "        1. The list containing model training loss is initialized.\n",
    "        2. The matplotlib figure is displayed.\n",
    "        3. The plot() function is called.\n",
    "        \"\"\"\n",
    "        self.losses = []\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "        self.plot()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        Executed when an epoch has finished.\n",
    "        \n",
    "        Here:\n",
    "        1. The model training loss for the epoch that finished is recorded.\n",
    "        2. The plot() function is called to update the graph.\n",
    "        \"\"\"\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.plot(epoch+1, plot_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation\n",
    "def data_generator(batch_size, emb_dim):\n",
    "    \"\"\"\n",
    "    Generates triplet batches during model training.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_size: int\n",
    "        How many triplets are in a batch.\n",
    "    emb_dim: int\n",
    "        The number of features in the embedding vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "        x, _ = create_batch(batch_size=batch_size)    # Without anchor_label\n",
    "        y = np.zeros((batch_size, 3*emb_dim))\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model\n",
    "Set the batch size, number of epochs, steps-per-spoch, and alpha margin value for triplet loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "\n",
    "# Number of triplets in batches.\n",
    "batch_size = 200   ## WARNING: Setting batch_size too high will result in a UnboundLocalError involving a log variable.\n",
    "\n",
    "# Number of epochs for model to train over.\n",
    "epochs = 100\n",
    "\n",
    "# Number of steps within an epoch.\n",
    "steps_per_epoch = int(num_train/batch_size)\n",
    "\n",
    "# Alpha margin value for triplet loss function.\n",
    "alpha = 0.5\n",
    "\n",
    "# Compile the model.\n",
    "net.compile(loss=triplet_loss(alpha=alpha, emb_dim=emb_dim), optimizer='adam')\n",
    "\n",
    "# Designate our test sets for plotting with PCAPlotter.\n",
    "X, Y = x_test[:1000], y_test[:1000]\n",
    "\n",
    "print(alpha)\n",
    "print(emb_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = net.fit(\n",
    "    data_generator(batch_size, emb_dim),\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    verbose=False,\n",
    "    callbacks=[\n",
    "        PCAPlotter(plt, embedding_model, X, Y)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@crimy/one-shot-learning-siamese-networks-and-triplet-loss-with-keras-2885ed022352\n",
    "\n",
    "def compute_dist(a,b):\n",
    "    \"\"\"Compute the Euclidean distance between a and b.\"\"\"\n",
    "    return np.sqrt(np.sum(np.square(a-b)))\n",
    "\n",
    "def compute_probs(network,X,Y):\n",
    "    '''\n",
    "    Input\n",
    "        network : current NN to compute embeddings\n",
    "        X : tensor of shape (m,w,h,1) containing pics to evaluate\n",
    "        Y : tensor of shape (m,) containing true class\n",
    "        \n",
    "    Returns\n",
    "        probs : array of shape (m,m) containing distances\n",
    "    \n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    nbevaluation = int(m*(m-1)/2)\n",
    "    probs = np.zeros((nbevaluation))\n",
    "    y = np.zeros((nbevaluation))\n",
    "    \n",
    "    # Compute all embeddings for all pics with current network\n",
    "    embeddings = network.predict(X)\n",
    "    \n",
    "    size_embedding = embeddings.shape[1]\n",
    "    \n",
    "    # For each pics of our dataset\n",
    "    k = 0\n",
    "    for i in range(m):\n",
    "            # Against all other images\n",
    "            for j in range(i+1,m):\n",
    "                # compute the probability of being the right decision : it should be 1 for right class, 0 for all other classes\n",
    "                probs[k] = -compute_dist(embeddings[i,:],embeddings[j,:])\n",
    "                if (Y[i]==Y[j]):\n",
    "                    y[k] = 1\n",
    "                else:\n",
    "                    y[k] = 0\n",
    "                k += 1\n",
    "    return probs,y\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "def compute_metrics(probs,yprobs):\n",
    "    '''\n",
    "    Returns\n",
    "        fpr : Increasing false positive rates such that element i is the false positive rate of predictions with score >= thresholds[i]\n",
    "        tpr : Increasing true positive rates such that element i is the true positive rate of predictions with score >= thresholds[i].\n",
    "        thresholds : Decreasing thresholds on the decision function used to compute fpr and tpr. thresholds[0] represents no instances being predicted and is arbitrarily set to max(y_score) + 1\n",
    "        auc : Area Under the ROC Curve metric\n",
    "    '''\n",
    "    # calculate AUC\n",
    "    auc = roc_auc_score(yprobs, probs)\n",
    "    # calculate roc curve\n",
    "    fpr, tpr, thresholds = roc_curve(yprobs, probs)\n",
    "    \n",
    "    return fpr, tpr, thresholds, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_val = 100\n",
    "\n",
    "# Computes the distances of the embeddings of the images against each other and\n",
    "# their probability of being correct.\n",
    "# probs - Contains the embedding distances.\n",
    "# yprob - Contains the probability of being correct.\n",
    "probs, yprob = compute_probs(embedding_model,x_test[:n_val],y_test[:n_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the false positive rate (FPR), the true positive rate (TPR), the thresholds on the decision function used to compute FPR and TPR,\n",
    "# and the area under the ROC Curve metric.\n",
    "fpr, tpr, thresholds, auc = compute_metrics(probs,yprob)\n",
    "print(fpr)\n",
    "print(tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sensitivity as function of false positive rate (fpr)\n",
    "sensitivity = tpr/(fpr+tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr,sensitivity); \n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve and Area under the curve (AUC)\n",
    "plt.figure()\n",
    "plt.plot(fpr,tpr, color='darkorange', lw=2, linestyle='-');\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--');\n",
    "plt.xlabel('False positive rate'); \n",
    "plt.ylabel('True positive rate');\n",
    "plt.title('AUC: {:.3f}'.format(auc))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Dp and Dn\n",
    "triplet, labels = create_batch(batch_size=1, anchor_label=0)\n",
    "\n",
    "myBatch = np.zeros((3, emb_dim))\n",
    "myBatch[0,:] = embedding_model.predict(triplet[0])\n",
    "myBatch[1,:] = embedding_model.predict(triplet[1])\n",
    "myBatch[2,:] = embedding_model.predict(triplet[2])\n",
    "plot_triplet(triplet, labels)\n",
    "\n",
    "# Calculate the Euclidean distance between the embeddings in myBatch\n",
    "from scipy.spatial.distance import cdist\n",
    "Y = cdist(myBatch, myBatch, 'euclidean')\n",
    "print(\"Dp: {}, Dn: {}\".format(Y[0,1],Y[0,2]))\n",
    "\n",
    "print(len(myBatch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at class embedding distance\n",
    "\n",
    "# Embed first 1000 test images\n",
    "num_sample = 50\n",
    "num_classes = 2\n",
    "junk = x_test[:num_sample]\n",
    "junky = y_test[:num_sample]\n",
    "emb_junk = np.zeros((num_sample,emb_dim))\n",
    "for i in range(num_sample):\n",
    "    emb_junk[i,:] = embedding_model.predict(np.expand_dims(junk[i,:], axis=0)) \n",
    "\n",
    "# Calculate euclidean distance between embeddings\n",
    "Y = cdist(emb_junk,emb_junk,'euclidean')\n",
    "\n",
    "# Populate class embedding distance matrix\n",
    "distance_matrix = np.zeros((num_classes,num_classes))\n",
    "counter = np.zeros((num_classes,num_classes))\n",
    "for i in range(num_sample):\n",
    "    for j in range(i+1,num_sample):\n",
    "        class1 = junky[i]\n",
    "        class2 = junky[j]\n",
    "        distance_matrix[class1,class2] += Y[i,j]\n",
    "        distance_matrix[class2,class1] += Y[i,j]\n",
    "        counter[class1,class2] += 1\n",
    "        counter[class2,class1] += 1\n",
    "distance_matrix = distance_matrix/counter\n",
    "\n",
    "# Visualize\n",
    "plt.figure(); plt.imshow(distance_matrix,interpolation='None'); \n",
    "plt.title(\"Class embedding distance\"); plt.colorbar(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See which classes are hard and easy to distinguish from each other\n",
    "\n",
    "# Input an integer here that represents a class. In the case of this network:\n",
    "# 0 = Single-Hit Image\n",
    "# 1 = Multi-Hit Image\n",
    "myClass = 0\n",
    "\n",
    "# select hardest and easiest classes based on mean distance\n",
    "dist = distance_matrix[myClass,:] \n",
    "challenging = np.argsort(dist)\n",
    "hardest = None\n",
    "hscore = 0\n",
    "easiest = None\n",
    "escore = 0\n",
    "cscore = dist[myClass]\n",
    "for i in challenging:\n",
    "    if i != myClass:\n",
    "        hardest = i\n",
    "        hscore=dist[i]\n",
    "        break\n",
    "for i in reversed(challenging):\n",
    "    if i != myClass:\n",
    "        easiest = i\n",
    "        escore=dist[i]\n",
    "        break        \n",
    "print(\"For PDB {} ({:.3f}), hardest class to distinguish is digit {} ({:.3f}) and easiest digit is {} ({:.3f})\"\n",
    "      .format(idx2hit[myClass],cscore,idx2hit[hardest],hscore,idx2hit[easiest],escore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy, Precision, Recall, and F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "def accuracy_precision_recall_and_f1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Returns the accuracy, precision, recall, and F1 scores.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: 1-D array-like\n",
    "        An array of the correct target values.\n",
    "        0 means single-hit and 1 means multi-hit (so double, triple, or quadruple).\n",
    "    y_pred: 1-D array-like\n",
    "        An array of the predicted target values by model.\n",
    "        0 means single-hit and 1 means multi-hit (so double, triple, or quadruple)\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    accuracy: float\n",
    "        The accuracy of the model on given test set.\n",
    "    precision: float\n",
    "        The precision of the model on given test set.\n",
    "    recall: float\n",
    "        The recall of the model on given test set.\n",
    "    f1_score: float\n",
    "        The F1 score of the model on given test set.\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    \n",
    "    # pos_label = 0 to return precision for classifying single-hit images.\n",
    "    precision = sklearn.metrics.precision_score(y_true=y_true, y_pred=y_pred, pos_label=0, average='binary', zero_division='warn')\n",
    "\n",
    "    # pos_label = 0 to return recall for classifying single-hit images.\n",
    "    recall = sklearn.metrics.recall_score(y_true=y_true, y_pred=y_pred, pos_label=0, average='binary', zero_division='warn')\n",
    "\n",
    "    # pos_label = 0 to return F1 score for classifying single-hit images.\n",
    "    f1_score = sklearn.metrics.f1_score(y_true=y_true, y_pred=y_pred, pos_label=0, average='binary', zero_division='warn')\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Using Anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def predict_using_anchors(anchor_single, anchor_multi, unknown):\n",
    "    \"\"\"\n",
    "    Predict whether an unknown image is a single-hit or multi-hit image by\n",
    "    comparing it against an anchor single-hit image and an anchor multi-hit image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    anchor_single: numpy.array\n",
    "        Anchor image for a single-hit image.\n",
    "    anchor_multi: numpy.array\n",
    "        Anchor image for multi-hit image.\n",
    "    unknown: numpy.array\n",
    "        Unknown image to get prediction from.\n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "    0 if the unknown image is single-hit and a 1 if the unknown image is a multi-hit.\n",
    "    \"\"\"\n",
    "    # Expand dimensions by one in axis 0 so that it matches input for embedding model.\n",
    "    anchor_single = np.expand_dims(anchor_single, axis=0)\n",
    "    anchor_multi = np.expand_dims(anchor_multi, axis=0)\n",
    "    unknown = np.expand_dims(unknown, axis=0)\n",
    "    \n",
    "    # Calculate the embedding vectors of the anchor single-hit image, anchor multi-hit image,\n",
    "    # and unknown image.\n",
    "    anc_single_emb = embedding_model.predict(anchor_single)\n",
    "    anc_multi_emb = embedding_model.predict(anchor_multi)\n",
    "    anc_unknown_emb = embedding_model.predict(unknown)\n",
    "    \n",
    "    # Calculate Euclidean distance between the embedding vectors\n",
    "    d_su = euclidean(anc_single_emb, anc_unknown_emb)  # Distance between anchor single-hit and unknown\n",
    "    d_mu = euclidean(anc_multi_emb, anc_unknown_emb)   # Distance between anchor multi-hit and unknown\n",
    "    \n",
    "    # Determine which distance is the smallest, and return a prediction\n",
    "    if (d_su < d_mu):\n",
    "        # Unknown image is single-hit\n",
    "        return 0\n",
    "    else:\n",
    "        # Unknown image is multi-hit\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMPY_GENERATOR_SEED = -1\n",
    "\n",
    "def sample_anchor_and_unknown_images(images, labels, seed=1234):\n",
    "    \"\"\"\n",
    "    Samples an anchor single-hit image, and anchor multi-hit image, and an unknown image\n",
    "    from given image dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    images: list(numpy.array)\n",
    "        List of diffraction images to sample multi-hit and single-hit images from.\n",
    "    labels: list(int)\n",
    "        List of integers representing the labels of the images given.\n",
    "        0 = single-hit\n",
    "        1 = multi-hit\n",
    "    seed: int (optional)\n",
    "        Seed used to initialize random number generation.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    (anc_single, anc_multi, unknown): tuple of numpy.array\n",
    "        anc_single: numpy.array\n",
    "            Anchor image for single-hit image.\n",
    "        anc_multi: numpy.array\n",
    "            Anchor image for multi-hit image.\n",
    "        unknown: numpy.array\n",
    "            Unknown image to compare against.\n",
    "            \n",
    "    (anc_single_label, anc_multi_label, unknown_label): tuple of int\n",
    "        anc_single_label: int\n",
    "            Integer representing the label of the anchor single-hit image.\n",
    "            Will always be 0 as it is a single-hit image.\n",
    "        anc_multi_label: int\n",
    "            Integer representing the label of the anchor multi-hit image.\n",
    "            Will always be 1 as it is a multi-hit image.\n",
    "        unknown_label: int\n",
    "            Integer representing the label of the unknown image.\n",
    "    \"\"\"\n",
    "    # Get global variable NUMPY_GENERATOR_SEED, which is used in this function.\n",
    "    global NUMPY_GENERATOR_SEED\n",
    "    \n",
    "    # Images to return\n",
    "    anc_single = None\n",
    "    anc_multi = None\n",
    "    unknown = None\n",
    "    \n",
    "    # Label of images to return\n",
    "    anc_single_label = None\n",
    "    anc_multi_label = None\n",
    "    unknown_label = None\n",
    "    \n",
    "    # Seed random number generator, if it hasn't already with given seed.\n",
    "    if NUMPY_GENERATOR_SEED != seed:\n",
    "        np.random.seed(seed=seed)\n",
    "        NUMPY_GENERATOR_SEED = seed\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # Get size of dataset.\n",
    "    dataset_size = len(images)\n",
    "    \n",
    "    # List of indices with single-hit images and multi-hit images\n",
    "    anc_single_indices = np.squeeze(np.where(labels == hit2idx['single_hit']))\n",
    "    anc_multi_indices = np.squeeze(np.where(labels == hit2idx['multi_hit']))\n",
    "    \n",
    "    # List of indices we got an anchor image from.\n",
    "    # Makes sure we do not accidently sample the same images for unknown image.\n",
    "    sampled_indices = []\n",
    "    \n",
    "    \"\"\"Get an anchor single-hit image\"\"\"\n",
    "    # 1. Get an index of a single-hit image.\n",
    "    idx = anc_single_indices[np.random.randint(0, high=len(anc_single_indices))]\n",
    "\n",
    "    # 2. Record that index in sampled_indices.\n",
    "    sampled_indices.append(idx)\n",
    "\n",
    "    # 3. Set anc_single as image at idx\n",
    "    anc_single = images[idx]\n",
    "\n",
    "    # 4. Set anc_single_label with label value\n",
    "    anc_single_label = labels[idx]\n",
    "        \n",
    "    \"\"\" Get an anchor multi-hit image \"\"\"\n",
    "    # 1. Get an index of a single-hit image.\n",
    "    idx = anc_multi_indices[np.random.randint(0, high=len(anc_multi_indices))]\n",
    "\n",
    "    # 2. Record that index in sampled_indices.\n",
    "    sampled_indices.append(idx)\n",
    "\n",
    "    # 3. Set anc_multi as image at idx.\n",
    "    anc_multi = images[idx]\n",
    "\n",
    "    # 4. Set anc_multi_label with label value.\n",
    "    anc_multi_label = labels[idx]\n",
    "        \n",
    "    \"\"\" Get an unknown image \"\"\"\n",
    "    while True:\n",
    "        # 1. Get a random index to look at.\n",
    "        idx = np.random.randint(0, high=dataset_size)\n",
    "        \n",
    "        # 2. Check to see if this idx was sampled before. If not, make this image the unknown image.\n",
    "        if (idx not in sampled_indices):\n",
    "            # Add idx to indices sampled.\n",
    "            sampled_indices.append(idx)\n",
    "            \n",
    "            # Set unknown as image at idx\n",
    "            unknown = images[idx]\n",
    "            \n",
    "            # Set unknown_label with label value\n",
    "            unknown_label = labels[idx]\n",
    "            \n",
    "            # Break from loop\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return (anc_single, anc_multi, unknown), (anc_single_label, anc_multi_label, unknown_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_N_predictions(x_test, y_test, img_dim, num_predictions=1, seed=1234):\n",
    "    \"\"\"\n",
    "    Given a list of images and labels, make N predictions from them using predict_using_anchors().\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_test: list(numpy.array)\n",
    "        Vectorized images, as numpy.array, that we would like to make predictions from.\n",
    "    y_test: list(int)\n",
    "        List of integers representing the labels of the images.\n",
    "        0 = Single-Hit\n",
    "        1 = Multi-Hit\n",
    "    img_dim: int\n",
    "        Dimension of vectorized images, defined as img_dim = number of rows * number of columns.\n",
    "    num_predictions: int (optional)\n",
    "        Number of predictions we would like to get from x_test images.\n",
    "    seed: int (optional)\n",
    "        Seeds random number generator used for sampling images to make a prediction out of.\n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "    predicted_images: numpy.array\n",
    "        numpy.array containing the unknown images that were classified by the model.\n",
    "    ground_truths: numpy.array\n",
    "        numpy.array of integers representing the ground truth values of the unknown images.\n",
    "        0 = Single-Hit\n",
    "        1 = Multi-Hit\n",
    "    predictions: list(int)\n",
    "        numpy.array of integers representing the predicted labels of the images.\n",
    "        0 = Single-Hit\n",
    "        1 = Multi-Hit\n",
    "    \"\"\"\n",
    "    # numpy arrays to return.\n",
    "    predicted_images = np.zeros((num_predictions, img_dim))   # img_dim was defined in \"vectorize dataset\" cell.\n",
    "    ground_truths = np.empty(num_predictions, dtype='uint8')\n",
    "    predictions = np.empty(num_predictions, dtype='uint8')\n",
    "\n",
    "    for i in range(num_predictions):\n",
    "        \n",
    "        # Sample an anchor single-hit image, an anchor multi-hit image, and an unknown image.\n",
    "        # (anc_single, anc_multi, unknown), (anc_single_label, anc_multi_label, unknown_label)\n",
    "        sampled_imgs, sampled_imgs_labels = sample_anchor_and_unknown_images(x_test, y_test, seed=seed)\n",
    "\n",
    "        # Extract anchor and unknown images.\n",
    "        anc_single = sampled_imgs[0]\n",
    "        anc_multi = sampled_imgs[1]\n",
    "        unknown = sampled_imgs[2]\n",
    "\n",
    "        # Extract anchor and unknown image labels.\n",
    "        anc_single_label = sampled_imgs_labels[0]\n",
    "        anc_multi_label = sampled_imgs_labels[1]\n",
    "        unknown_label = sampled_imgs_labels[2]\n",
    "        \n",
    "        # Make a prediction using the sampled images.\n",
    "        prediction = predict_using_anchors(anc_single, anc_multi, unknown)\n",
    "        \n",
    "        # Add unknown image, ground truth label, and prediction label to numpy arrays that will be returned.\n",
    "        predicted_images[i] = unknown\n",
    "        ground_truths[i] = unknown_label\n",
    "        predictions[i] = prediction\n",
    "        \n",
    "    return predicted_images, ground_truths, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a test image batch for testing the model now that it is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a batch of \"raw\" triplets. That is, a batch of anchor, positive, and negative triplets.\n",
    "test_img_raw, test_labels_raw = create_batch(batch_size=1000)\n",
    "\n",
    "# Extract anchor images and labels from the \"raw\" triplets\n",
    "test_imgs = test_img_raw[0]\n",
    "test_labels = test_labels_raw[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions using the test image batch generated in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_imgs, ground_truths, preds = make_N_predictions(test_imgs, test_labels, img_dim, num_predictions=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute accuracy, precision, recall, and F1 score of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy, precision, recall, and F1 score of model on a test set.\n",
    "accuracy, precision, recall, f1 = accuracy_precision_recall_and_f1(ground_truths, preds)\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "print('Precision: {}'.format(precision))\n",
    "print('Recall: {}'.format(recall))\n",
    "print('F1 Score: {}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create visualization of model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Run on psana\n",
    "tf.keras.utils.plot_model(\n",
    "    net,\n",
    "    to_file=\"twin_network.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create collage of labeled diffraction images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import numpy as np\n",
    "from textwrap import wrap\n",
    "from pylab import cm\n",
    "\n",
    "# Font, font size, and axes line width of plots.\n",
    "mpl.rcParams['font.family'] = 'Avenir'\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['axes.linewidth'] = 0\n",
    "\n",
    "# Images to plot with their predicted and ground-truth labels.\n",
    "# From \"Make predictions using the test image batch generated in the cell above.\" cell.\n",
    "imgs = pred_imgs[0:20]\n",
    "true_values = ground_truths[0:20]\n",
    "predictions = preds[0:20]\n",
    "\n",
    "# Setup the collage plot.\n",
    "nrows = 4\n",
    "ncols = 5\n",
    "vmin = 0\n",
    "vmax = 5\n",
    "plt.figure(figsize=(30, 30))\n",
    "\n",
    "# Plot the collage.\n",
    "for idx in range(len(imgs)):\n",
    "    \n",
    "    # Predicted and ground truth labels for img.\n",
    "    str_true_label = idx2hit[true_values[idx]]\n",
    "    str_prediction_label = idx2hit[predictions[idx]]\n",
    "    \n",
    "    # Setup matplotlib subplot\n",
    "    plt.subplot(nrows, ncols, idx + 1)\n",
    "    \n",
    "    # Set subplot title as \"Prediction\"/\"Ground Truth\"\n",
    "    plt.title(str_prediction_label + ' / ' + str_true_label)\n",
    "    \n",
    "    # Plot the diffraction image.\n",
    "    plt.imshow(np.reshape(imgs[idx], (dim_r, dim_c)), vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    # Add colorbar of image map.\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # Turn off axis labels, so that we have the image with colorbar next to it.\n",
    "    plt.axis('off')\n",
    "\n",
    "# Save classification collage with publication quality.\n",
    "image_name = 'classified_images.png'\n",
    "plt.savefig(image_name, dpi=300, transparent=False, bbox_inches='tight')\n",
    "\n",
    "# Show the collage.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import numpy as np\n",
    "from textwrap import wrap\n",
    "from pylab import cm\n",
    "\n",
    "def display_diffraction_img_and_prediction(random_number):\n",
    "\n",
    "    # Edit the font, font size, and axes width\n",
    "    mpl.rcParams['font.family'] = 'Avenir'\n",
    "    plt.rcParams['font.size'] = 20\n",
    "    plt.rcParams['axes.linewidth'] = 0\n",
    "\n",
    "    # Images to possibly display.\n",
    "    imgs = x_test[1]     # Get positive images.\n",
    "    predictions = y_pred\n",
    "    true_values = y_true\n",
    "\n",
    "    # Setup the matplotlib plot.\n",
    "    nrows = 1\n",
    "    ncols = 1\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "    fig.set_size_inches((4, 4))\n",
    "\n",
    "    # Prediction and ground truth labels.\n",
    "    str_classified_label = ''\n",
    "    str_true_label = ''\n",
    "    \n",
    "    # Determine the prediction label.\n",
    "    if (predictions[random_number] == 0):\n",
    "        # Single-hit classified\n",
    "        str_classified_label = 'Prediction: Single-Hit'\n",
    "    else:\n",
    "        # Multi-hit classified\n",
    "        str_classified_label = 'Prediction: Multi-Hit'\n",
    "        \n",
    "    # Determine the ground truth label.\n",
    "    if (true_values[random_number] == 0):\n",
    "        # Single-hit true\n",
    "        str_true_label = 'Ground Truth: Single-Hit'\n",
    "    else:\n",
    "        # Multi-hit true\n",
    "        str_true_label = 'Ground Truth: Multi-Hit'\n",
    "    \n",
    "    # Set the plot's title to be \"Prediction\" on the first line and \"Ground Truth\"\n",
    "    # on the next line.\n",
    "    axs.set_title(str_classified_label + '\\n' + str_true_label)\n",
    "    \n",
    "    # set visibility of x-axis as False\n",
    "    xax = axs.axes.get_xaxis()\n",
    "    xax = xax.set_visible(False)\n",
    "  \n",
    "    # set visibility of y-axis as False\n",
    "    yax = axs.axes.get_yaxis()\n",
    "    yax = yax.set_visible(False)\n",
    "    \n",
    "    # Plot the diffraction image at the location of the given random number.\n",
    "    axs.imshow(np.reshape(imgs[random_number], (dim_r, dim_c)), vmin=0, vmax=3)\n",
    "\n",
    "    # Display the image with prediction and ground truth values.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo\n",
    "### Pick a number between 0 and 999 to see a diffraction image, as well as the prediction the twin neural network made!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RANDOM_NUMBER = 100\n",
    "display_diffraction_img_and_prediction(RANDOM_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
