{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Create a Siamese Network with Triplet Loss in Keras\n",
    "import socket\n",
    "print(socket.gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import h5py\n",
    "import pydot\n",
    "import graphviz\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle2idx = {\n",
    "    '1fpv': 0,\n",
    "    '1ss8': 1,\n",
    "    '3j03': 2,\n",
    "    '1ijg': 3,\n",
    "    '3iyf': 4,\n",
    "    '6ody': 5,\n",
    "    '6sp2': 6,\n",
    "    '6xs6': 7,\n",
    "    '7dwz': 8,\n",
    "    '7dx8': 9,\n",
    "    '7dx9': 10\n",
    "}\n",
    "\n",
    "count2idx = {\n",
    "    'single': 0,\n",
    "    'double': 1,\n",
    "    'triple': 2,\n",
    "    'quadruple': 3\n",
    "}\n",
    "\n",
    "hit2idx = {\n",
    "    'single_hit': 0,\n",
    "    'multi_hit': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2particle = {\n",
    "    0: '1fpv',\n",
    "    1: '1ss8',\n",
    "    2: '3j03',\n",
    "    3: '1ijg',\n",
    "    4: '3iyf',\n",
    "    5: '6ody',\n",
    "    6: '6sp2',\n",
    "    7: '6xs6',\n",
    "    8: '7dwz',\n",
    "    9: '7dx8',\n",
    "    10: '7dx9'\n",
    "}\n",
    "\n",
    "idx2count = {\n",
    "    0: 'single',\n",
    "    1: 'double',\n",
    "    2: 'triple',\n",
    "    3: 'quadruple'\n",
    "}\n",
    "\n",
    "idx2hit = {\n",
    "    0: 'single_hit',\n",
    "    1: 'multi_hit'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNoise(orig_img, flux_jitter=0.9, gaussian_noise=0.15):\n",
    "\n",
    "    def changeIntensity(img, flux_jitter):\n",
    "        factor = 100 # FIXME: correct for data which has 100 more flux\n",
    "        mu = 1 # mean jitter\n",
    "        alpha = np.random.normal(mu, flux_jitter)\n",
    "        if alpha <= 0: alpha = 0.1 # alpha can't be zero\n",
    "        n_photons = alpha*np.sum(img) / factor                     # number of desired photons per image\n",
    "        return n_photons*(img/np.sum(img)) # cache noise-free measurement\n",
    "    \n",
    "    def poisson(img):\n",
    "        # add poisson noise\n",
    "        return np.random.poisson(img)      # apply Poisson statistics\n",
    "    \n",
    "    def gaussian(img, sigma):\n",
    "        # add gaussian noise \n",
    "        # For random samples from N(\\mu, \\sigma^2), \n",
    "        # mu + sigma * np.random.randn(...)\n",
    "        # sigma: Gaussian noise level\n",
    "        img = img + sigma*np.random.randn(*img.shape);  # apply Gaussian statistics\n",
    "        return img\n",
    "    \n",
    "    def varNorm(V):\n",
    "        # variance normalization, each image has mean 0, variance 1\n",
    "        # This shouldn't happen, but zero out infinite pixels\n",
    "        V[np.argwhere(V==np.inf)] = 0\n",
    "        mean = np.mean(V)\n",
    "        std = np.std(V)\n",
    "        if std == 0:\n",
    "            return np.zeros_like(V)\n",
    "        V1 = (V-mean)/std\n",
    "        return V1\n",
    "    \n",
    "    def rotation_transform(img, rotation_range):\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        img = tf.keras.preprocessing.image.random_rotation(x=img, rg=rotation_range, row_axis=0, col_axis=1, channel_axis=2,\n",
    "                                                           fill_mode='constant', cval=0.0)\n",
    "        img = np.squeeze(img)\n",
    "        return img\n",
    "    \n",
    "    def vertical_flip_transform(img):\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        img = tf.image.random_flip_left_right(img).numpy()\n",
    "        img = np.squeeze(img)\n",
    "        return img\n",
    "    \n",
    "    def horizontal_flip_transform(img):\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        img = tf.image.random_flip_up_down(img).numpy()\n",
    "        img = np.squeeze(img)\n",
    "        return img\n",
    "    \n",
    "    def zoom_transform(img, zoom_range):\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        img = tf.keras.preprocessing.image.random_zoom(x=img, zoom_range=zoom_range, row_axis=0, col_axis=1, channel_axis=2,\n",
    "                                                       fill_mode='constant', cval=0.0)\n",
    "        img = np.squeeze(img)\n",
    "        return img\n",
    "        \n",
    "\n",
    "    def transform(img):\n",
    "        # Apply rotation, flips, and zooms before other noise.\n",
    "        img = rotation_transform(img, rotation_range=360)\n",
    "        img = vertical_flip_transform(img)\n",
    "        img = horizontal_flip_transform(img)\n",
    "        img = zoom_transform(img, zoom_range=(0.9, 1.1))\n",
    "        \n",
    "        img = changeIntensity(img, flux_jitter)\n",
    "        img = poisson(img)\n",
    "        img = gaussian(img, gaussian_noise)\n",
    "        img = varNorm(img)\n",
    "        return img\n",
    "    \n",
    "    # \"orig_img\" is actually a \"mini-batch\" of images.\n",
    "    # This loops applies the transforms to every image in that \"mini-batch\"\n",
    "    for i in range(orig_img.shape[0]):\n",
    "        orig_img[i] = transform(img=orig_img[i])\n",
    "    \n",
    "    return orig_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loads data and label them by count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(num_train_samples=200, num_test_samples=50, normalize=None, seed=None):\n",
    "    \"\"\"\n",
    "    num_train_samples: number of training samples\n",
    "    num_test_samples: number of test samples\n",
    "    normalize: type of intensity normalization {'variance'}\n",
    "    seed: random seed\n",
    "    \"\"\"\n",
    "    # num_train_sample must be divisible by 2\n",
    "    path = '/reg/data/ana03/scratch/xericfl/DeepProjection/DeepProjection/resnet/eric_data/'\n",
    "    \n",
    "    ### Change these names\n",
    "    fnames = ['1fpv_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '6sp2_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '1ijg_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '6xs6_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '1ss8_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '7dwz_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '3iyf_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '7dx8_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '3j03_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '7dx9_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '6ody_5k_single_pps_1e14_thumbnail.h5',\n",
    "            '1fpv_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '6sp2_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '1ijg_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '6xs6_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '1ss8_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '7dwz_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '3iyf_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '7dx8_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '3j03_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '7dx9_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '6ody_5k_double_pps_1e14_thumbnail.h5',\n",
    "            '1fpv_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '6sp2_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '1ijg_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '6xs6_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '1ss8_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '7dwz_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '3iyf_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '7dx8_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '3j03_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '7dx9_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '6ody_5k_triple_pps_1e14_thumbnail.h5',\n",
    "            '1fpv_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '6sp2_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '1ijg_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '6xs6_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '1ss8_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '7dwz_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '3iyf_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '7dx8_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '3j03_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '7dx9_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "            '6ody_5k_quadruple_pps_1e14_thumbnail.h5']\n",
    "            \n",
    "    numFiles = len(fnames)\n",
    "    \n",
    "    if seed is not None: \n",
    "        np.random.seed(seed)\n",
    "    # Get image dimensions\n",
    "    with h5py.File(path+fnames[0],'r') as f:\n",
    "        img = f['photons'][0,:,:]\n",
    "        nR,nC = img.shape\n",
    "            \n",
    "    # TRAIN\n",
    "    x_train = np.empty((num_train_samples, nR, nC), dtype='float32')\n",
    "    y_train = np.empty((num_train_samples,), dtype='uint8')\n",
    "    index = np.random.randint(0, numFiles, num_train_samples)\n",
    "    for i, fname in enumerate(fnames):\n",
    "        ind = np.where(index == i)[0]\n",
    "        if len(ind) > 0:\n",
    "            with h5py.File(path+fname,'r') as f:\n",
    "                \n",
    "                x_train[ind] = addNoise(f['photons'][0:len(ind),:,:], flux_jitter=0.9, gaussian_noise=0.15)\n",
    "                print(fname, len(ind))\n",
    "                \n",
    "                # Get particle count\n",
    "                if 'single' in fname:\n",
    "                    y_train[ind] = hit2idx['single_hit']\n",
    "                elif ('double' in fname) or ('triple' in fname) or ('quadruple' in fname):\n",
    "                    y_train[ind] = hit2idx['multi_hit']\n",
    "                else:\n",
    "                    raise Exception('Unknown file being processed. Be sure that one of the following count types are in the file name: \\\"single\\\", \\\"double\\\", \\\"triple\\\", or \\\"quadruple\\\"')\n",
    "\n",
    "\n",
    "    # TEST\n",
    "    x_test = np.empty((num_test_samples, nR, nC), dtype='float32')\n",
    "    y_test = np.empty((num_test_samples,), dtype='uint8')\n",
    "    index = np.random.randint(0,numFiles,num_test_samples)\n",
    "    for i, fname in enumerate(fnames):\n",
    "        ind = np.where(index == i)[0] \n",
    "        if len(ind) > 0:\n",
    "            with h5py.File(path+fname,'r') as f:\n",
    "                # apply offset since first num_train_samples have been used\n",
    "                offset = round(num_train_samples/numFiles)\n",
    "                \n",
    "                x_test[ind] = addNoise(f['photons'][offset:len(ind)+offset,:,:], flux_jitter=0.9, gaussian_noise=0.15)\n",
    "                    \n",
    "                if 'single' in fname:\n",
    "                    y_test[ind] = hit2idx['single_hit']\n",
    "                elif ('double' in fname) or ('triple' in fname) or ('quadruple' in fname):\n",
    "                    y_test[ind] = hit2idx['multi_hit']\n",
    "                else:\n",
    "                    raise Exception('Unknown file being processed. Be sure that one of the following count types are in the file name: \\\"single\\\", \\\"double\\\", \\\"triple\\\", or \\\"quadruple\\\"')\n",
    "\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loads data and label them by PDB ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import diffraction image set\n",
    "\n",
    "# def load_data(num_train_samples=200, num_test_samples=50, normalize=None, seed=None):\n",
    "#     \"\"\"\n",
    "#     num_train_samples: number of training samples\n",
    "#     num_test_samples: number of test samples\n",
    "#     normalize: type of intensity normalization {'variance'}\n",
    "#     seed: random seed\n",
    "#     \"\"\"\n",
    "#     # num_train_sample must be divisible by 2\n",
    "#     path = '/reg/data/ana03/scratch/xericfl/DeepProjection/DeepProjection/resnet/eric_data/'\n",
    "    \n",
    "#     ### Change these names\n",
    "#     fnames = ['1fpv_5k_single_pps_1e14_thumbnail.h5',\n",
    "#             '6sp2_5k_single_pps_1e14_thumbnail.h5',\n",
    "#             '1ijg_5k_single_pps_1e14_thumbnail.h5',\n",
    "#             '6xs6_5k_single_pps_1e14_thumbnail.h5',\n",
    "#             '1ss8_5k_single_pps_1e14_thumbnail.h5',\n",
    "#             '7dwz_5k_single_pps_1e14_thumbnail.h5',\n",
    "#             '3iyf_5k_single_pps_1e14_thumbnail.h5',\n",
    "#             '7dx8_5k_single_pps_1e14_thumbnail.h5',\n",
    "#             '3j03_5k_single_pps_1e14_thumbnail.h5',\n",
    "#             '7dx9_5k_single_pps_1e14_thumbnail.h5',\n",
    "#             '6ody_5k_single_pps_1e14_thumbnail.h5',\n",
    "#             '1fpv_5k_double_pps_1e14_thumbnail.h5',\n",
    "#             '6sp2_5k_double_pps_1e14_thumbnail.h5',\n",
    "#             '1ijg_5k_double_pps_1e14_thumbnail.h5',\n",
    "#             '6xs6_5k_double_pps_1e14_thumbnail.h5',\n",
    "#             '1ss8_5k_double_pps_1e14_thumbnail.h5',\n",
    "#             '7dwz_5k_double_pps_1e14_thumbnail.h5',\n",
    "#             '3iyf_5k_double_pps_1e14_thumbnail.h5',\n",
    "#             '7dx8_5k_double_pps_1e14_thumbnail.h5',\n",
    "#             '3j03_5k_double_pps_1e14_thumbnail.h5',\n",
    "#             '7dx9_5k_double_pps_1e14_thumbnail.h5',\n",
    "#             '6ody_5k_double_pps_1e14_thumbnail.h5',\n",
    "#             '1fpv_5k_triple_pps_1e14_thumbnail.h5',\n",
    "#             '6sp2_5k_triple_pps_1e14_thumbnail.h5',\n",
    "#             '1ijg_5k_triple_pps_1e14_thumbnail.h5',\n",
    "#             '6xs6_5k_triple_pps_1e14_thumbnail.h5',\n",
    "#             '1ss8_5k_triple_pps_1e14_thumbnail.h5',\n",
    "#             '7dwz_5k_triple_pps_1e14_thumbnail.h5',\n",
    "#             '3iyf_5k_triple_pps_1e14_thumbnail.h5',\n",
    "#             '7dx8_5k_triple_pps_1e14_thumbnail.h5',\n",
    "#             '3j03_5k_triple_pps_1e14_thumbnail.h5',\n",
    "#             '7dx9_5k_triple_pps_1e14_thumbnail.h5',\n",
    "#             '6ody_5k_triple_pps_1e14_thumbnail.h5',\n",
    "#             '1fpv_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "#             '6sp2_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "#             '1ijg_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "#             '6xs6_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "#             '1ss8_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "#             '7dwz_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "#             '3iyf_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "#             '7dx8_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "#             '3j03_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "#             '7dx9_5k_quadruple_pps_1e14_thumbnail.h5',\n",
    "#             '6ody_5k_quadruple_pps_1e14_thumbnail.h5']\n",
    "    \n",
    "#     numFiles = len(fnames)\n",
    "    \n",
    "#     if seed is not None: \n",
    "#         np.random.seed(seed)\n",
    "#     # Get image dimensions\n",
    "#     with h5py.File(path+fnames[0],'r') as f:\n",
    "#         img = f['photons'][0,:,:]\n",
    "#         nR,nC = img.shape\n",
    "            \n",
    "#     # TRAIN\n",
    "#     x_train = np.empty((num_train_samples, nR, nC), dtype='float32')\n",
    "#     y_train = np.empty((num_train_samples,), dtype='uint8')\n",
    "#     index = np.random.randint(0,numFiles,num_train_samples)\n",
    "#     for i, fname in enumerate(fnames):\n",
    "#         ind = np.where(index == i)[0]\n",
    "#         if len(ind) > 0:\n",
    "#             with h5py.File(path+fname,'r') as f:\n",
    "#                 x_train[ind] = f['photons'][0:len(ind),:,:]\n",
    "#                 print(fname, len(ind))\n",
    "                \n",
    "#                 for idx in range(len(idx2particle)):\n",
    "#                     if idx2particle[idx] in fname:\n",
    "#                         y_train[ind] = idx\n",
    "                \n",
    "\n",
    "#     # TEST\n",
    "#     x_test = np.empty((num_test_samples, nR, nC), dtype='float32')\n",
    "#     y_test = np.empty((num_test_samples,), dtype='uint8')\n",
    "#     index = np.random.randint(0,numFiles,num_test_samples)\n",
    "#     for i, fname in enumerate(fnames):\n",
    "#         ind = np.where(index == i)[0] \n",
    "#         if len(ind) > 0:\n",
    "#             with h5py.File(path+fname,'r') as f:\n",
    "#                 # apply offset since first num_train_samples have been used\n",
    "#                 offset = round(num_train_samples/numFiles)\n",
    "#                 x_test[ind] = f['photons'][offset:len(ind)+offset,:,:]\n",
    "                \n",
    "#                 for idx in range(len(idx2particle)):\n",
    "#                     if idx2particle[idx] in fname:\n",
    "#                         y_test[ind] = idx\n",
    "        \n",
    "#     #x_train = tf.expand_dims(x_train, axis=1)\n",
    "#     #x_train = x_train.numpy()\n",
    "\n",
    "#     #x_test = tf.expand_dims(x_test, axis=1)\n",
    "#     #x_test = x_test.numpy()\n",
    "    \n",
    "#     return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "(x_train, y_train), (x_test, y_test) = load_data(num_train_samples=200, num_test_samples=50, normalize=None, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize dataset\n",
    "print(x_train.shape)\n",
    "(num_train, dim_r, dim_c) = x_train.shape\n",
    "num_test = x_test.shape[0]\n",
    "img_dim = dim_r * dim_c\n",
    "\n",
    "x_train = np.reshape(x_train, (num_train, img_dim)) # reshape to vectors\n",
    "x_test = np.reshape(x_test, (num_test, img_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting triplet (anchor, positive, negative)\n",
    "def plot_triplet(triplet, labels):\n",
    "    plt.figure(figsize=(6,2))\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.imshow(np.reshape(triplet[i], (dim_r, dim_c)), cmap='binary')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "           \n",
    "        if i == 0: plt.title('anchor: {}'.format(idx2hit[labels[i].item()]))\n",
    "        if i == 1: plt.title('positive: {}'.format(idx2hit[labels[i].item()]))\n",
    "        if i == 2: plt.title('negative: {}'.format(idx2hit[labels[i].item()]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a batch of triplets\n",
    "def create_batch(batch_size, anchor_label=None):\n",
    "    anchors = np.zeros((batch_size, img_dim))\n",
    "    positives = np.zeros((batch_size, img_dim))\n",
    "    negatives = np.zeros((batch_size, img_dim))\n",
    "    \n",
    "    # Holds labels, where [ind, 0] contains PDB ID and [ind, 1] contains count classification\n",
    "    anchor_labels = np.zeros((batch_size,), dtype=int)\n",
    "    positive_labels = np.zeros((batch_size,), dtype=int)\n",
    "    negative_labels = np.zeros((batch_size,), dtype=int)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Pick an anchor that matches anchor_label if given\n",
    "        if anchor_label is not None:\n",
    "            indices_for_anc = np.squeeze(np.where(y_train == anchor_label))\n",
    "            index = indices_for_anc[np.random.randint(0, len(indices_for_anc)-1)]\n",
    "        else:\n",
    "            index = np.random.randint(0, num_train-1)\n",
    "        \n",
    "        anc = x_train[index]\n",
    "        y = y_train[index]\n",
    "        \n",
    "        indices_for_pos = np.squeeze(np.where(y_train == y))\n",
    "        indices_for_neg = np.squeeze(np.where(y_train != y))\n",
    "        \n",
    "        pos_idx = indices_for_pos[np.random.randint(0, len(indices_for_pos)-1)]\n",
    "        neg_idx = indices_for_neg[np.random.randint(0, len(indices_for_neg)-1)]\n",
    "        \n",
    "        pos = x_train[pos_idx]\n",
    "        neg = x_train[neg_idx]\n",
    "        \n",
    "        anchors[i] = anc\n",
    "        positives[i] = pos\n",
    "        negatives[i] = neg\n",
    "        \n",
    "        anchor_labels[i] = y\n",
    "        positive_labels[i] = y_train[pos_idx]\n",
    "        negative_labels[i] = y_train[neg_idx]\n",
    "        \n",
    "    # Returns image batches and (anc, pos, neg) labels\n",
    "    return [anchors, positives, negatives], [anchor_labels, positive_labels, negative_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a batch of triplet\n",
    "triplet, labels = create_batch(batch_size=1, anchor_label=0)\n",
    "plot_triplet(triplet, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model (2 dense layers w/ relu and sigmoid activation)\n",
    "#### Play with this value during testing.\n",
    "emb_dim = 32\n",
    "\n",
    "# Dense implements the operation: output = activation(dot(input, kernel) + bias)\n",
    "\n",
    "#### TODO: Implement CNN or Resnet model you want for embeddings here\n",
    "embedding_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(emb_dim, activation='relu', input_shape=(img_dim,)),\n",
    "    tf.keras.layers.Dense(emb_dim, activation='sigmoid')\n",
    "])\n",
    "\n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example = x_train[0]\n",
    "example_emb = embedding_model.predict(np.expand_dims(example, axis=0))\n",
    "print(\"example embedding: \", example_emb, example_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(example_emb[0],'x-'); plt.xlabel(\"features\"); plt.ylabel(\"weight\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese network\n",
    "in_anc = tf.keras.layers.Input(shape=(img_dim,))\n",
    "in_pos = tf.keras.layers.Input(shape=(img_dim,))\n",
    "in_neg = tf.keras.layers.Input(shape=(img_dim,))\n",
    "\n",
    "em_anc = embedding_model(in_anc)\n",
    "em_pos = embedding_model(in_pos)\n",
    "em_neg = embedding_model(in_neg)\n",
    "\n",
    "out = tf.keras.layers.concatenate([em_anc, em_pos, em_neg], axis=1)\n",
    "\n",
    "net = tf.keras.models.Model(\n",
    "    [in_anc, in_pos, in_neg],\n",
    "    out\n",
    ")\n",
    "\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Loss\n",
    "A loss function that tries to pull the Embeddings of Anchor and Positive Examples closer, and tries to push the Embeddings of Anchor and Negative Examples away from each other.\n",
    "\n",
    "Root mean square difference between Anchor and Positive examples in a batch of N images is:\n",
    "$\n",
    "\\begin{equation}\n",
    "d_p = \\sqrt{\\frac{\\sum_{i=0}^{N-1}(f(a_i) - f(p_i))^2}{N}}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "Root mean square difference between Anchor and Negative examples in a batch of N images is:\n",
    "$\n",
    "\\begin{equation}\n",
    "d_n = \\sqrt{\\frac{\\sum_{i=0}^{N-1}(f(a_i) - f(n_i))^2}{N}}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "For each example, we want:\n",
    "$\n",
    "\\begin{equation}\n",
    "d_p \\leq d_n\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "Therefore,\n",
    "$\n",
    "\\begin{equation}\n",
    "d_p - d_n \\leq 0\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "This condition is quite easily satisfied during the training.\n",
    "\n",
    "We will make it non-trivial by adding a margin (alpha):\n",
    "$\n",
    "\\begin{equation}\n",
    "d_p - d_n + \\alpha \\leq 0\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "Given the condition above, the Triplet Loss L is defined as:\n",
    "$\n",
    "\\begin{equation}\n",
    "L = max(d_p - d_n + \\alpha, 0)\n",
    "\\end{equation}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(alpha, emb_dim):\n",
    "    def loss(y_true, y_pred):\n",
    "        anc, pos, neg = y_pred[:, :emb_dim], y_pred[:, emb_dim:2*emb_dim], y_pred[:, 2*emb_dim:]\n",
    "        dp = tf.reduce_mean(tf.square(anc - pos), axis=1)\n",
    "        dn = tf.reduce_mean(tf.square(anc - neg), axis=1)\n",
    "        return tf.maximum(dp - dn + alpha, 0.)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAPlotter(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, plt, embedding_model, x_test, y_test):\n",
    "        super(PCAPlotter, self).__init__()\n",
    "        self.embedding_model = embedding_model\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.fig = plt.figure(figsize=(10, 10))\n",
    "        self.ax1 = plt.subplot(1, 2, 1)\n",
    "        self.ax2 = plt.subplot(1, 2, 2)\n",
    "        plt.ion()\n",
    "        \n",
    "        self.losses = []\n",
    "    \n",
    "    def plot(self, epoch=None, plot_loss=False):\n",
    "        x_test_embeddings = self.embedding_model.predict(self.x_test)\n",
    "        pca_out = PCA(n_components=2).fit_transform(x_test_embeddings)\n",
    "        self.ax1.clear()\n",
    "        self.ax1.scatter(pca_out[:, 0], pca_out[:, 1], c=self.y_test, cmap='seismic')\n",
    "        if plot_loss:\n",
    "            self.ax2.clear()\n",
    "            self.ax2.plot(range(epoch), self.losses)\n",
    "            self.ax2.set_xlabel('Epochs')\n",
    "            self.ax2.set_ylabel('Loss')\n",
    "            self.ax2.set_title('Loss vs Epochs')\n",
    "        self.ax1.set_title('PCA embedding of Siamese embedding')\n",
    "        self.ax1.set_xlabel('principal component 1')\n",
    "        self.ax1.set_ylabel('principal component 2')\n",
    "        self.fig.canvas.draw()\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.losses = []\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "        self.plot()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.plot(epoch+1, plot_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation\n",
    "def data_generator(batch_size, emb_dim):\n",
    "    while True:\n",
    "        x, _ = create_batch(batch_size=batch_size)    # Without anchor_label\n",
    "        y = np.zeros((batch_size, 3*emb_dim))\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "\n",
    "#### TODO: Run bigger batch size on SDF or another psana node.\n",
    "batch_size = 200   #### BEWARE: Setting batch_size too high will result in a UnboundLocalError involving a log variable.\n",
    "epochs = 100\n",
    "steps_per_epoch = int(num_train/batch_size)\n",
    "alpha = 0.5\n",
    "\n",
    "net.compile(loss=triplet_loss(alpha=alpha, emb_dim=emb_dim), optimizer='adam')\n",
    "\n",
    "X, Y = x_test[:1000], y_test[:1000]\n",
    "\n",
    "print(alpha)\n",
    "print(emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = net.fit(\n",
    "    data_generator(batch_size, emb_dim),\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    verbose=False,\n",
    "    callbacks=[\n",
    "        PCAPlotter(plt, embedding_model, X, Y)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@crimy/one-shot-learning-siamese-networks-and-triplet-loss-with-keras-2885ed022352\n",
    "\n",
    "def compute_dist(a,b):\n",
    "    return np.sum(np.square(a-b))\n",
    "\n",
    "def compute_probs(network,X,Y):\n",
    "    '''\n",
    "    Input\n",
    "        network : current NN to compute embeddings\n",
    "        X : tensor of shape (m,w,h,1) containing pics to evaluate\n",
    "        Y : tensor of shape (m,) containing true class\n",
    "        \n",
    "    Returns\n",
    "        probs : array of shape (m,m) containing distances\n",
    "    \n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    nbevaluation = int(m*(m-1)/2)\n",
    "    probs = np.zeros((nbevaluation))\n",
    "    y = np.zeros((nbevaluation))\n",
    "    \n",
    "    #Compute all embeddings for all pics with current network\n",
    "    embeddings = network.predict(X)\n",
    "    \n",
    "    size_embedding = embeddings.shape[1]\n",
    "    \n",
    "    #For each pics of our dataset\n",
    "    k = 0\n",
    "    for i in range(m):\n",
    "            #Against all other images\n",
    "            for j in range(i+1,m):\n",
    "                #compute the probability of being the right decision : it should be 1 for right class, 0 for all other classes\n",
    "                probs[k] = -compute_dist(embeddings[i,:],embeddings[j,:])\n",
    "                if (Y[i]==Y[j]):\n",
    "                    y[k] = 1\n",
    "                else:\n",
    "                    y[k] = 0\n",
    "                k += 1\n",
    "    return probs,y\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "def compute_metrics(probs,yprobs):\n",
    "    '''\n",
    "    Returns\n",
    "        fpr : Increasing false positive rates such that element i is the false positive rate of predictions with score >= thresholds[i]\n",
    "        tpr : Increasing true positive rates such that element i is the true positive rate of predictions with score >= thresholds[i].\n",
    "        thresholds : Decreasing thresholds on the decision function used to compute fpr and tpr. thresholds[0] represents no instances being predicted and is arbitrarily set to max(y_score) + 1\n",
    "        auc : Area Under the ROC Curve metric\n",
    "    '''\n",
    "    # calculate AUC\n",
    "    auc = roc_auc_score(yprobs, probs)\n",
    "    # calculate roc curve\n",
    "    fpr, tpr, thresholds = roc_curve(yprobs, probs)\n",
    "    \n",
    "    return fpr, tpr, thresholds, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_val = 100\n",
    "probs,yprob = compute_probs(embedding_model,x_test[:n_val],y_test[:n_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds, auc = compute_metrics(probs,yprob)\n",
    "print(fpr)\n",
    "print(tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sensitivity as function of false positive rate (fpr)\n",
    "sensitivity = tpr/(fpr+tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr,sensitivity); \n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve and Area under the curve (AUC)\n",
    "plt.figure()\n",
    "plt.plot(fpr,tpr, color='darkorange', lw=2, linestyle='-');\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--');\n",
    "plt.xlabel('False positive rate'); \n",
    "plt.ylabel('True positive rate');\n",
    "plt.title('AUC: {:.3f}'.format(auc))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Dp and Dn\n",
    "triplet, labels = create_batch(batch_size=1, anchor_label=0)\n",
    "\n",
    "myBatch = np.zeros((3, emb_dim))\n",
    "myBatch[0,:] = embedding_model.predict(triplet[0])\n",
    "myBatch[1,:] = embedding_model.predict(triplet[1])\n",
    "myBatch[2,:] = embedding_model.predict(triplet[2])\n",
    "plot_triplet(triplet, labels)\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "Y = cdist(myBatch, myBatch, 'euclidean')\n",
    "print(\"Dp: {}, Dn: {}\".format(Y[0,1],Y[0,2]))\n",
    "\n",
    "print(len(myBatch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at class embedding distance\n",
    "\n",
    "# Embed first 1000 test images\n",
    "num_sample = 50\n",
    "num_classes = 2\n",
    "junk = x_test[:num_sample]\n",
    "junky = y_test[:num_sample]\n",
    "emb_junk = np.zeros((num_sample,emb_dim))\n",
    "for i in range(num_sample):\n",
    "    emb_junk[i,:] = embedding_model.predict(np.expand_dims(junk[i,:], axis=0)) \n",
    "\n",
    "# Calculate euclidean distance between embeddings\n",
    "Y = cdist(emb_junk,emb_junk,'euclidean')\n",
    "\n",
    "# Populate class embedding distance matrix\n",
    "distance_matrix = np.zeros((num_classes,num_classes))\n",
    "counter = np.zeros((num_classes,num_classes))\n",
    "for i in range(num_sample):\n",
    "    for j in range(i+1,num_sample):\n",
    "        class1 = junky[i]\n",
    "        class2 = junky[j]\n",
    "        distance_matrix[class1,class2] += Y[i,j]\n",
    "        distance_matrix[class2,class1] += Y[i,j]\n",
    "        counter[class1,class2] += 1\n",
    "        counter[class2,class1] += 1\n",
    "distance_matrix = distance_matrix/counter\n",
    "\n",
    "# Visualize\n",
    "plt.figure(); plt.imshow(distance_matrix,interpolation='None'); \n",
    "plt.title(\"Class embedding distance\"); plt.colorbar(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See which classes are hard and easy to distinguish from each other\n",
    "\n",
    "myClass = 0 # Choose a digit here\n",
    "\n",
    "# select hardest and easiest classes based on mean distance\n",
    "dist = distance_matrix[myClass,:] \n",
    "challenging = np.argsort(dist)\n",
    "hardest = None\n",
    "hscore = 0\n",
    "easiest = None\n",
    "escore = 0\n",
    "cscore = dist[myClass]\n",
    "for i in challenging:\n",
    "    if i != myClass:\n",
    "        hardest = i\n",
    "        hscore=dist[i]\n",
    "        break\n",
    "for i in reversed(challenging):\n",
    "    if i != myClass:\n",
    "        easiest = i\n",
    "        escore=dist[i]\n",
    "        break        \n",
    "print(\"For PDB {} ({:.3f}), hardest class to distinguish is digit {} ({:.3f}) and easiest digit is {} ({:.3f})\"\n",
    "      .format(idx2hit[myClass],cscore,idx2hit[hardest],hscore,idx2hit[easiest],escore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retabulate y_true and y_pred.\n",
    "At the moment, y_true and y_pred contains idx2count values for the individual particle counts used: 0 = single, 1 = double, 2 = triple, and 3 = quadruple. Here, we will turn this multi-classification into a binary classification, where 0 = single-hit images and 1 = multi-hit images (of double, triple, and quadruple)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_from_embeddings(embeddings, test_labels, emb_dim):\n",
    "    \n",
    "    # Retrieve the anchor, positive, and negative embeddings.\n",
    "    anc, pos, neg = embeddings[:, :emb_dim], embeddings[:, emb_dim:2*emb_dim], embeddings[:, 2*emb_dim:]\n",
    "    \n",
    "    y_pred = np.zeros(len(embeddings), dtype=int)\n",
    "    \n",
    "    for i in range(len(embeddings)):\n",
    "        batch_embeddings = np.zeros((3, emb_dim))\n",
    "        batch_embeddings[0,:] = anc[i]\n",
    "        batch_embeddings[1,:] = pos[i]\n",
    "        batch_embeddings[2,:] = neg[i]\n",
    "        \n",
    "        Y = cdist(batch_embeddings, batch_embeddings, 'euclidean')\n",
    "        dp = Y[0,1]\n",
    "        dn = Y[0,2]\n",
    "        \n",
    "        anchor_label = test_labels[0][i].item()\n",
    "        pos_label = test_labels[1][i].item()\n",
    "        neg_label = test_labels[2][i].item()\n",
    "        \n",
    "        # Debug\n",
    "        #print('Anchor: {}'.format(anchor_label))\n",
    "        #print('Positive: {}'.format(pos_label))\n",
    "        #print('Negative: {}'.format(neg_label))\n",
    "        #print('dp: {}'.format(dp))\n",
    "        #print('dn: {}'.format(dn))\n",
    "        \n",
    "        if (anchor_label == hit2idx['single_hit']) and (pos_label == hit2idx['single_hit']):\n",
    "        \n",
    "            # The anchor and positive images are SINGLE-HIT images. So if dp < dn, the network classifies a SINGLE-HIT image.\n",
    "            if (dp < dn):\n",
    "                y_pred[i] = hit2idx['single_hit']\n",
    "            else:\n",
    "                y_pred[i] = hit2idx['multi_hit']\n",
    "        \n",
    "        elif (anchor_label == hit2idx['multi_hit']) and (pos_label == hit2idx['multi_hit']):\n",
    "            \n",
    "            # The anchor and positive images are MULTI-HIT images. So if dp < dn, the network classifies a MULTI-HIT image.\n",
    "            if (dp < dn):\n",
    "                y_pred[i] = hit2idx['multi_hit']\n",
    "            else:\n",
    "                y_pred[i] = hit2idx['single_hit']\n",
    "        \n",
    "        else:\n",
    "            # Not sure what to put here.\n",
    "            pass\n",
    "            \n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 1000\n",
    "\n",
    "# Create a batch to get accuracy, precision, recall, and F1 scores from.\n",
    "x_test, y_test = create_batch(batch_size=test_batch_size)\n",
    "\n",
    "# Get y_true.\n",
    "y_true = np.ones(test_batch_size, dtype=int)\n",
    "for i in range(test_batch_size):\n",
    "    \n",
    "    # If anchor and positive image are single-hit\n",
    "    if y_test[0][i].item() == 0 and y_test[1][i].item() == 0:\n",
    "        y_true[i] = hit2idx['single_hit']\n",
    "    elif y_test[0][i].item() == 1 and y_test[0][i].item() == 1:\n",
    "        y_true[i] = hit2idx['multi_hit']\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Get embeddings for the batch.\n",
    "predict_embeddings = net.predict(x_test)\n",
    "\n",
    "# Classify embeddings\n",
    "y_pred = get_predictions_from_embeddings(embeddings=predict_embeddings, test_labels=y_test, emb_dim=emb_dim)\n",
    "\n",
    "\n",
    "#print('Predicted values: ' + str(y_pred))\n",
    "#print('True values: ' + str(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy, Precision, Recall, and F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "def accuracy_precision_recall_and_f1(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns the precision, recall, and F1 scores.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true -> An array of the correct target values. 0 means single-hit and 1 means multi-hit (so double, triple, or quadruple).\n",
    "    y_false -> An array of the predicted target values by model. 0 means single-hit and 1 means multi-hit (so double, triple, or quadruple)\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    \n",
    "    # pos_label = 0 to return precision for classifying single-hit images.\n",
    "    precision = sklearn.metrics.precision_score(y_true=y_true, y_pred=y_pred, pos_label=0, average='binary', zero_division='warn')\n",
    "\n",
    "    # pos_label = 0 to return recall for classifying single-hit images.\n",
    "    recall = sklearn.metrics.recall_score(y_true=y_true, y_pred=y_pred, pos_label=0, average='binary', zero_division='warn')\n",
    "\n",
    "    # pos_label = 0 to return F1 score for classifying single-hit images.\n",
    "    f1_score = sklearn.metrics.f1_score(y_true=y_true, y_pred=y_pred, pos_label=0, average='binary', zero_division='warn')\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1 = accuracy_precision_recall_and_f1(y_true, y_pred)\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "print('Precision: {}'.format(precision))\n",
    "print('Recall: {}'.format(recall))\n",
    "print('F1 Score: {}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import numpy as np\n",
    "from textwrap import wrap\n",
    "from pylab import cm\n",
    "\n",
    "def display_diffraction_img_and_prediction(random_number):\n",
    "\n",
    "    # Edit the font, font size, and axes width\n",
    "    mpl.rcParams['font.family'] = 'Avenir'\n",
    "    plt.rcParams['font.size'] = 20\n",
    "    plt.rcParams['axes.linewidth'] = 0\n",
    "\n",
    "    # Images\n",
    "    imgs = x_test[1]     # Get positive images.\n",
    "    predictions = y_pred\n",
    "    true_values = y_true\n",
    "\n",
    "    nrows = 1\n",
    "    ncols = 1\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "    fig.set_size_inches((4, 4))\n",
    "\n",
    "    str_classified_label = ''\n",
    "    str_true_label = ''\n",
    "    \n",
    "    if (predictions[random_number] == 0):\n",
    "        # Single-hit classified\n",
    "        str_classified_label = 'Prediction: Single-Hit'\n",
    "    else:\n",
    "        # Multi-hit classified\n",
    "        str_classified_label = 'Prediction: Multi-Hit'\n",
    "        \n",
    "        \n",
    "    if (true_values[random_number] == 0):\n",
    "        # Single-hit true\n",
    "        str_true_label = 'Ground Truth: Single-Hit'\n",
    "    else:\n",
    "        # Multi-hit true\n",
    "        str_true_label = 'Ground Truth: Multi-Hit'\n",
    "    \n",
    "    axs.set_title(str_classified_label + '\\n' + str_true_label)\n",
    "    \n",
    "    # set visibility of x-axis as False\n",
    "    xax = axs.axes.get_xaxis()\n",
    "    xax = xax.set_visible(False)\n",
    "  \n",
    "    # set visibility of y-axis as False\n",
    "    yax = axs.axes.get_yaxis()\n",
    "    yax = yax.set_visible(False)\n",
    "    \n",
    "    axs.imshow(np.reshape(imgs[random_number], (dim_r, dim_c)), vmin=0, vmax=3)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create visualization of model archecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    net,\n",
    "    to_file=\"twin_network.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create collage of labeled diffraction images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_test[1]))\n",
    "print(x_test[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import numpy as np\n",
    "from textwrap import wrap\n",
    "from pylab import cm\n",
    "\n",
    "# Edit the font, font size, and axes width\n",
    "mpl.rcParams['font.family'] = 'Avenir'\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['axes.linewidth'] = 0\n",
    "\n",
    "# Images\n",
    "imgs = x_test[1][20:40]\n",
    "predictions = y_pred[20:40]\n",
    "true_values = y_true[20:40]\n",
    "print(predictions)\n",
    "\n",
    "nrows = 4\n",
    "ncols = 5\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "fig.set_size_inches((24, 24))\n",
    "\n",
    "curr_row = 0\n",
    "curr_col = 0\n",
    "idx = 0\n",
    "for img in imgs:\n",
    "    \n",
    "    str_classified_label = ''\n",
    "    str_true_label = ''\n",
    "    \n",
    "    if (predictions[idx] == 0):\n",
    "        # Single-hit classified\n",
    "        str_classified_label = 'Single-Hit'\n",
    "    else:\n",
    "        # Multi-hit classified\n",
    "        str_classified_label = 'Multi-Hit'\n",
    "        \n",
    "        \n",
    "    if (true_values[idx] == 0):\n",
    "        # Single-hit true\n",
    "        str_true_label = 'Single-Hit'\n",
    "    else:\n",
    "        # Multi-hit true\n",
    "        str_true_label = 'Multi-Hit'\n",
    "        \n",
    "    \n",
    "    idx = idx + 1\n",
    "    \n",
    "    axs[curr_row, curr_col].set_title(str_classified_label + ' / ' + str_true_label)\n",
    "    \n",
    "    # set visibility of x-axis as False\n",
    "    xax = axs[curr_row, curr_col].axes.get_xaxis()\n",
    "    xax = xax.set_visible(False)\n",
    "  \n",
    "    # set visibility of y-axis as False\n",
    "    yax = axs[curr_row, curr_col].axes.get_yaxis()\n",
    "    yax = yax.set_visible(False)\n",
    "    \n",
    "    axs[curr_row, curr_col].imshow(np.reshape(img, (dim_r, dim_c)), vmin=0, vmax=5)\n",
    "    \n",
    "    curr_col = curr_col + 1\n",
    "    \n",
    "    if (curr_col == ncols):\n",
    "        curr_col = 0\n",
    "        curr_row = curr_row + 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "image_name = 'classified_images.png'\n",
    "plt.savefig(image_name, dpi=300, transparent=False, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo\n",
    "### Pick a number between 0 and 999 to see a diffraction image, as well as the prediction the twin neural network made!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RANDOM_NUMBER = 100\n",
    "display_diffraction_img_and_prediction(RANDOM_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
