{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs from the [following paper](http://cs230.stanford.edu/projects_spring_2021/reports/54.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import socket\n",
    "print(socket.gethostname())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models from multioutput_cnns.py\n",
    "from multioutput_cnns import MultiOutputCNN_3Layer, MultiOutputCNN_5Layer, MultiOutputCNN_10Layer, MultiOutputCNN_18Layer, MultiOutputCNN_Early, CustomResNet18Model, CustomVgg16Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2076,
     "status": "ok",
     "timestamp": 1621182233169,
     "user": {
      "displayName": "Enci Liu",
      "photoUrl": "",
      "userId": "13274077478020183171"
     },
     "user_tz": 420
    },
    "id": "ocNRQsIznK8n",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import argparse\n",
    "from argparse import Namespace\n",
    "\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorboard\n",
    "# from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from resnet import resnet18, resnet34, resnet50\n",
    "from datetime import datetime as dt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7gi1BCstuFv"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle2idx = {\n",
    "    '1fpv': 0,\n",
    "    '1ss8': 1,\n",
    "    '3j03': 2,\n",
    "    '1ijg': 3,\n",
    "    '3iyf': 4,\n",
    "    '6ody': 5,\n",
    "    '6sp2': 6,\n",
    "    '6xs6': 7,\n",
    "    '7dwz': 8,\n",
    "    '7dx8': 9,\n",
    "    '7dx9': 10\n",
    "}\n",
    "\n",
    "count2idx = {\n",
    "    'single': 0,\n",
    "    'double': 1,\n",
    "    'triple': 2,\n",
    "    'quadruple': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2particle = {\n",
    "    0: '1fpv',\n",
    "    2: '1ss8',\n",
    "    2: '3j03',\n",
    "    3: '1ijg',\n",
    "    4: '3iyf',\n",
    "    5: '6ody',\n",
    "    6: '6sp2',\n",
    "    7: '6xs6',\n",
    "    8: '7dwz',\n",
    "    9: '7dx8',\n",
    "    10: '7dx9'\n",
    "}\n",
    "\n",
    "idx2count = {\n",
    "    0: 'single',\n",
    "    1: 'double',\n",
    "    2: 'triple',\n",
    "    3: 'quadruple'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, particles, counts, transform=None, seed=1234):\n",
    "        \"\"\"\n",
    "        CustomDataset is used to contain diffraction images used in model training.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        root_dir: str\n",
    "            String representing the directory path of the diffraction image datasets.\n",
    "        particles: list(str)\n",
    "            List of strings representing the PDB IDs of the particles being used for model training.\n",
    "        counts: list(str)\n",
    "            List of strings representing the particle count of the images being used for model training.\n",
    "        transform: torchvision.transforms.Compose\n",
    "            A torchvision.transforms.Compose object containing the transforms to apply to the diffraction images.\n",
    "        seed: int\n",
    "            An integer used to seed the randomization of the order of the data.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.count_labels = []\n",
    "        self.particle_labels = []\n",
    "        self.data = []\n",
    "\n",
    "        for particle in particles:\n",
    "            for count in counts:\n",
    "                \n",
    "                # Create directory path to dataset\n",
    "                n = 5    # Used in generating the file names of files to open; n = 5 will open up 5k image datasets\n",
    "                data_dir = f'{self.root_dir}/{particle}_{str(n)}k_{count}_pps_1e14_thumbnail.h5'\n",
    "\n",
    "                # Load images as h5 files\n",
    "                f = h5py.File(data_dir, 'r')\n",
    "                dset_name = list(f.keys())[0]\n",
    "                data = f[dset_name]\n",
    "                data = [Image.fromarray(data[i]) for i in range(LENGTH * n)]   # Converts data into PIL images.\n",
    "                \n",
    "                # DEBUG\n",
    "                # Display 20 of the original images\n",
    "                #print('Original shape: ' + str(data[0].size))\n",
    "                #fig = plt.figure(figsize=(15, 15))\n",
    "                #fig.suptitle('Original', y=0.91, fontsize=16)\n",
    "                #columns = 4\n",
    "                #rows = 5\n",
    "                #for i in range(1, columns * rows + 1):\n",
    "                #    img = np.array(data[i - 1])\n",
    "                #    fig.add_subplot(rows, columns, i)\n",
    "                #    plt.imshow(img, vmin=0, vmax=25)\n",
    "                #    plt.colorbar()\n",
    "                #plt.show()\n",
    "                \n",
    "                # Apply transforms to images\n",
    "                data = [self.transform(data[i]) for i in range(LENGTH * n)]\n",
    "                \n",
    "                # DEBUG\n",
    "                # Display 20 of the transformed images\n",
    "                #print('Transformed shape: ' + str(data[0].shape))\n",
    "                #fig = plt.figure(figsize=(15, 15))\n",
    "                #fig.suptitle('Transformed From Original', y=0.91, fontsize=16)\n",
    "                #columns = 4\n",
    "                #rows = 5\n",
    "                #for i in range(1, columns * rows + 1):\n",
    "                #    img = data[i - 1].numpy()\n",
    "                #    img = np.squeeze(img)\n",
    "                #    fig.add_subplot(rows, columns, i)\n",
    "                #    plt.imshow(img, vmin=0, vmax=25)\n",
    "                #    plt.colorbar()\n",
    "                #plt.show()\n",
    "                \n",
    "                # Apply image labels\n",
    "                count_label = [count2idx[count]] * (LENGTH * n)\n",
    "                particle_label = [particle2idx[particle]] * (LENGTH * n)\n",
    "                self.data.extend(data)\n",
    "                self.count_labels.extend(count_label)\n",
    "                self.particle_labels.extend(particle_label)\n",
    "        \n",
    "        # Shuffle the data\n",
    "        random.seed(seed)\n",
    "        perm = list(range(len(self.data)))\n",
    "        random.shuffle(perm)\n",
    "        self.data = [self.data[i] for i in perm]\n",
    "        self.count_labels = [self.count_labels[i] for i in perm]\n",
    "        self.particle_labels = [self.particle_labels[i] for i in perm]\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Denotes the total number of samples'''\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Generates one sample of data'''\n",
    "        X = self.data[index]\n",
    "        count = self.count_labels[index]\n",
    "        particle = self.particle_labels[index]\n",
    "        return X, count, particle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AddNoise Class: A wrapper for the addNoise() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNoise(object):\n",
    "    \"\"\"\n",
    "    A wrapper for addNoise(), so that it can be used with other torch transform functions.\n",
    "    AddNoise applies the following noise to images:\n",
    "        1. Reduce the fluence by a factor of 100.\n",
    "        2. Add poisson noise.\n",
    "        3. Add gaussian noise given a sigma value.\n",
    "        4. Varience normalization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, flux_jitter, gaussian_noise):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        flux_jitter: float\n",
    "            Flux jitter to use when reducing the fluence of the image.\n",
    "            \n",
    "        gaussian_noise: float\n",
    "            Alias for sigma to be used in gaussian distribution. Sets how much\n",
    "            gaussian noise to apply to image.\n",
    "        \"\"\"\n",
    "        assert isinstance(flux_jitter, float)\n",
    "        assert isinstance(gaussian_noise, float)\n",
    "        self.flux_jitter = flux_jitter\n",
    "        self.gaussian_noise = gaussian_noise\n",
    "\n",
    "    def __call__(self, image):\n",
    "        \"\"\" Called by PyTorch when applying the AddNoise transform. \"\"\"\n",
    "        return self.addNoise(image)\n",
    "\n",
    "    def addNoise(self, orig_img):\n",
    "        \"\"\"\n",
    "        Applies the following noise to a given image:\n",
    "            1. Reduce the fluence by a factor of 100.\n",
    "            2. Add poisson noise.\n",
    "            3. Add gaussian noise given a sigma value.\n",
    "            4. Varience normalization.\n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        orig_img: PIL Image\n",
    "            Image to apply noise to.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        PIL Image\n",
    "            Image with noise applied to it.\n",
    "        \"\"\"\n",
    "        \n",
    "        def changeIntensity(img, flux_jitter):\n",
    "            factor = 100 # Reduces the fluence of the image by a factor of 100. Ex. 1e14 photons/pulse -> 1e12 photons/pulse.\n",
    "            mu = 1 # mean jitter\n",
    "            alpha = np.random.normal(mu, flux_jitter)\n",
    "            if alpha <= 0: alpha = 0.1 # alpha can't be zero\n",
    "            n_photons = alpha*np.sum(img) / factor                     # number of desired photons per image\n",
    "            return n_photons*(img/np.sum(img)) # cache noise-free measurement\n",
    "    \n",
    "        def poisson(img):\n",
    "            # add poisson noise\n",
    "            return np.random.poisson(img)      # apply Poisson statistics\n",
    "    \n",
    "        def gaussian(img, sigma):\n",
    "            # add gaussian noise \n",
    "            # For random samples from N(\\mu, \\sigma^2), \n",
    "            # mu + sigma * np.random.randn(...)\n",
    "            # sigma: Gaussian noise level\n",
    "            img = img + sigma*np.random.randn(*img.shape);  # apply Gaussian statistics\n",
    "            return img\n",
    "    \n",
    "        def varNorm(V):\n",
    "            # variance normalization, each image has mean 0, variance 1\n",
    "            # This shouldn't happen, but zero out infinite pixels\n",
    "            V[np.argwhere(V==np.inf)] = 0\n",
    "            mean = np.mean(V)\n",
    "            std = np.std(V)\n",
    "            if std == 0:\n",
    "                return np.zeros_like(V)\n",
    "            V1 = (V-mean)/std\n",
    "            return V1\n",
    "\n",
    "        def transform(img):\n",
    "            img = changeIntensity(img, self.flux_jitter)\n",
    "            img = poisson(img)\n",
    "            img = gaussian(img, self.gaussian_noise)\n",
    "            img = varNorm(img)\n",
    "            return img\n",
    "        \n",
    "        return Image.fromarray(transform(orig_img))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1621182238687,
     "user": {
      "displayName": "Enci Liu",
      "photoUrl": "",
      "userId": "13274077478020183171"
     },
     "user_tz": 420
    },
    "id": "d_-YQ56vVwhn"
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(args, train_val_particles, test_particles, test_diff_particle=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates torch.utils.data.DataLoader objects for the training, validation, and testing. Part of this includes applying augmentations and noise to the diffraction images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    args\n",
    "        args.num_particles: int\n",
    "            Number of unique particles in train_val_particles and test_particles.\n",
    "        args.root_dir: str\n",
    "            String representation of directory containing the data needed for training/testing.\n",
    "        args.batch_size: int\n",
    "            Batch size for DataLoaders.\n",
    "        args.shuffle: bool\n",
    "            Shuffle the data in DataLoaders.\n",
    "        args.num_workers: int\n",
    "            Number of subprocesses to use for data loading.\n",
    "    \n",
    "    train_val_particles: list(str)\n",
    "        List of str representing the PDB IDs of particles used for training and validation sets.\n",
    "\n",
    "    test_particles: list(str) \n",
    "        List of str representing the PDB IDs of particles used for test sets.\n",
    "\n",
    "    test_diff_particle: bool\n",
    "        If True, create a test dataloader that uses a different set of particles not specified in train_val_particles or test_particles.\n",
    "        If False, create a test dataloader that uses the same set of particles specified in train_val_particles/test_particles; train_val_particles and test_particles must be the same!\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    A training DataLoader, a validation DataLoader, and a test DataLoader.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Augmentations and noise applied to images:\n",
    "    # 1. CenterCrop(128): Crops image at the center with an output size of (128, 128).\n",
    "    # 2. RandomVerticalFlip(p=0.5): Flips image vertically with 50% probability.\n",
    "    # 3. RandomHorizontalFlip(p=0.5): Flips image horizontally with 50% probability.\n",
    "    # 4. RandomAffine(degrees=360, scale(0.9, 1.1)): Random rotation w/ range of (-360, 360) and random zoom w/ range of (0.9x, 1.1x).\n",
    "    # 5. AddNoise(0.9, 0.15): Applies noise with flux jitter of 0.9 and gaussian noise of 0.15.\n",
    "    # 6. ToTensor(): Convert image to PyTorch tensor.\n",
    "    transform = transforms.Compose([transforms.CenterCrop(128),\n",
    "                                    transforms.RandomVerticalFlip(p=0.5),\n",
    "                                    transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                    transforms.RandomAffine(degrees=360, scale=(0.9, 1.1)),\n",
    "                                    AddNoise(flux_jitter=0.9, gaussian_noise=0.15),\n",
    "                                    transforms.ToTensor()])\n",
    "    \n",
    "    # Total number of images in datasets.\n",
    "    # 20000 = (5k single images) + (5k double images) + (5k triple images) + (5k quadruple images)\n",
    "    data_len = args.num_particles * 20000\n",
    "    \n",
    "    if not test_diff_particle: # Create train, validation, and test datasets using the same set of particles.\n",
    "        assert train_val_particles == test_particles\n",
    "        dataset = CustomDataset(root_dir=args.root_dir,\n",
    "                                particles=train_val_particles,\n",
    "                                counts=COUNTS,\n",
    "                                transform=transform)\n",
    "        \n",
    "        # Split the data into a train, validation, and test set as follows:\n",
    "        # The first 70% of the dataset is for the training dataset.\n",
    "        # The next 10% of the dataset is for the validation dataset.\n",
    "        # The last 20% of the dataset is for the test dataset.\n",
    "        train_idx = list(range(0, int(data_len * 0.7)))\n",
    "        valid_idx = list(range(int(data_len * 0.7), int(data_len * 0.8)))\n",
    "        test_idx = list(range(int(data_len * 0.8), data_len))\n",
    "        \n",
    "        # More information on PyTorch Subset: https://pytorch.org/docs/stable/data.html\n",
    "        # Create the train, validation, and test datasets.\n",
    "        train_dataset = Subset(dataset, train_idx) \n",
    "        valid_dataset = Subset(dataset, valid_idx)\n",
    "        test_dataset = Subset(dataset, test_idx)\n",
    "    else: # Create train and validation datasets using the same set of particles, and the test dataset with a different set of particles.\n",
    "        \n",
    "        # Create train/valid/test datasets\n",
    "        train_val_dataset = CustomDataset(root_dir=args.root_dir, \n",
    "                                          particles=train_val_particles,\n",
    "                                          counts=COUNTS,\n",
    "                                          transform=transform)\n",
    "        \n",
    "        # More information on PyTorch Subset: https://pytorch.org/docs/stable/data.html\n",
    "        # Split the data into a train and validation set as follows:\n",
    "        # The first 7000 diffraction images is for the training dataset.\n",
    "        # The next 1000 diffraction images is for the validation dataset.\n",
    "        train_idx = list(range(0, 7000))\n",
    "        valid_idx = list(range(7000, 8000))\n",
    "        \n",
    "        # Create the train, validation, and test datasets.\n",
    "        train_dataset = Subset(train_val_dataset, train_idx) \n",
    "        valid_dataset = Subset(train_val_dataset, valid_idx)\n",
    "        \n",
    "        # The test dataset in this case contains diffraction images of particles not in\n",
    "        # the training nor validation set.\n",
    "        test_dataset = CustomDataset(root_dir=args.root_dir, \n",
    "                                    particles=test_particles,\n",
    "                                    counts=COUNTS,\n",
    "                                    transform=transform)\n",
    "        \n",
    "        # Check to see that the images in the train, validation, and test datasets\n",
    "        # have the same shape of (1, 128, 128).\n",
    "        assert train_dataset.__getitem__(0)[0].shape == torch.Size([1, 128, 128])\n",
    "        assert valid_dataset.__getitem__(0)[0].shape == torch.Size([1, 128, 128])\n",
    "        assert test_dataset.__getitem__(0)[0].shape == torch.Size([1, 128, 128])\n",
    "\n",
    "    # Create train/valid/test dataloaders\n",
    "    train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  shuffle=args.shuffle, \n",
    "                                  num_workers=args.num_workers)\n",
    "    valid_dataloader = DataLoader(dataset=valid_dataset,\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  shuffle=args.shuffle, \n",
    "                                  num_workers=args.num_workers)\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, \n",
    "                                 batch_size=args.batch_size, \n",
    "                                 shuffle=args.shuffle, \n",
    "                                 num_workers=args.num_workers)\n",
    "    return train_dataloader, valid_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xNRaiMqZUt5"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1621182654483,
     "user": {
      "displayName": "Enci Liu",
      "photoUrl": "",
      "userId": "13274077478020183171"
     },
     "user_tz": 420
    },
    "id": "90SAviZnS3vz"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, dataloader):\n",
    "    \"\"\"Evaluate the model on `num_steps` batches.\n",
    "    Args:\n",
    "        model: (torch.nn.Module) the neural network\n",
    "        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
    "        dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches data\n",
    "        \n",
    "    Return:\n",
    "        accuracy: float\n",
    "            Overall accuracy of the model.\n",
    "        count_accuracy: float\n",
    "            Accuracy of model in identifying whether an image is single-hit or multi-hit (ex. double, triple, quadruple).\n",
    "        particle_accuracy: float\n",
    "            Accuracy of model in identifying the particle from diffraction images.\n",
    "        loss: float\n",
    "            Loss of the model a training step.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Evaluate the model using PyTorch's eval()\n",
    "    model.eval()\n",
    "\n",
    "    # Initial necessary lists and loss variables.\n",
    "    accuracies = []\n",
    "    loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    preds1 = []\n",
    "    preds2 = []\n",
    "    all_count_labels = []\n",
    "    all_particle_labels = []\n",
    "    all_images = []\n",
    "    \n",
    "    for i, (inputs, count_labels, particle_labels) in enumerate(dataloader):\n",
    "        \n",
    "        # Send images to device.\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        if not args.multi_output: # If the model IS NOT multi-output...\n",
    "            # Get predictions from model.\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Calculate the loss for the batch.\n",
    "            batch_loss = loss_fn(outputs, count_labels.squeeze(0).to(device))\n",
    "            \n",
    "            # Add batch loss to total loss.\n",
    "            loss += batch_loss\n",
    "            \n",
    "            # Record predictions and loss.\n",
    "            preds = torch.argmax(outputs, dim=-1)\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(count_labels)\n",
    "            \n",
    "            loss = loss / len(dataloader)\n",
    "        else: # If the model IS multi-output...\n",
    "            \n",
    "            # y1 contains predictions for particle COUNT classification.\n",
    "            # y2 contains predictions for particle PDB ID classification.\n",
    "            y1, y2 = model(inputs)\n",
    "            \n",
    "            # loss1 is model loss for particle COUNT classification.\n",
    "            # loss2 is model loss for particle PDB ID classification.\n",
    "            loss1 = loss_fn(y1, count_labels.squeeze(0).to(device)).detach().item()\n",
    "            loss2 = loss_fn(y2, particle_labels.squeeze(0).to(device)).detach().item()\n",
    "            \n",
    "            # Total loss of the batch.\n",
    "            # This is a weighted loss, with the loss from COUNT classification having more weight.\n",
    "            # Mentioned in Section 4.2 of paper mentioned at the top of the notebook.\n",
    "            batch_loss = 4 * loss1 + loss2\n",
    "            \n",
    "            # Add batch loss to total loss.\n",
    "            loss += batch_loss\n",
    "            \n",
    "            # Convert particle count and id predictions to a list.\n",
    "            y1 = torch.argmax(y1, dim=-1).to('cpu').numpy().tolist()\n",
    "            y2 = torch.argmax(y2, dim=-1).to('cpu').numpy().tolist()\n",
    "            \n",
    "            # Record predictions.\n",
    "            preds1.extend(y1)\n",
    "            preds2.extend(y2)\n",
    "            all_images.extend(inputs)\n",
    "            all_count_labels.extend(count_labels.to('cpu').numpy().tolist())\n",
    "            all_particle_labels.extend(particle_labels.to('cpu').numpy().tolist())\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Total accuracy\n",
    "    correct_pred = [1 if (preds1[i] == all_count_labels[i] and preds2[i] == all_particle_labels[i]) else 0 for i in range(len(preds1))]\n",
    "    accuracy = sum(correct_pred) / len(preds1) * 100\n",
    "    \n",
    "    # Count accuracy\n",
    "    correct_pred_count = [1 if (preds1[i] == all_count_labels[i]) else 0 for i in range(len(preds1))]\n",
    "    count_accuracy = sum(correct_pred_count) / len(preds1) * 100\n",
    "    \n",
    "    # Particle accuracy\n",
    "    correct_pred_particle = [1 if (preds2[i] == all_particle_labels[i]) else 0 for i in range(len(preds2))]\n",
    "    particle_accuracy = sum(correct_pred_particle) / len(preds1) * 100\n",
    "    \n",
    "    loss = loss / len(dataloader)\n",
    "    \n",
    "    # Compute accuracy for each particle type\n",
    "    particle_acc_dict = {}\n",
    "    for idx in idx2particle:\n",
    "        temp = {}\n",
    "        temp['crct'] = sum([1 if (preds2[i] == idx and preds2[i] == all_particle_labels[i]) else 0 for i in range(len(preds2))])\n",
    "        temp['total'] = sum([1 if (all_particle_labels[i] == idx) else 0 for i in range(len(all_particle_labels))])\n",
    "        particle_acc_dict[idx2particle[idx]] = temp['crct'] / temp['total']\n",
    "        if idx2particle[idx] == '7dx8':\n",
    "            wrong_pred_7dx8 = [preds2[i] if (all_particle_labels[i] == idx and preds2[i] != all_particle_labels[i]) else None for i in range(len(preds2))]\n",
    "    print(particle_acc_dict)\n",
    "\n",
    "    return accuracy, count_accuracy, particle_accuracy, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1n0r3qXAtzEx"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 579,
     "status": "ok",
     "timestamp": 1621182655834,
     "user": {
      "displayName": "Enci Liu",
      "photoUrl": "",
      "userId": "13274077478020183171"
     },
     "user_tz": 420
    },
    "id": "18sO4iAot0bH"
   },
   "outputs": [],
   "source": [
    "def train(args, model, optimizer, loss_fn):\n",
    "    \"\"\"\n",
    "    Train the network on the training data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args\n",
    "        args.epoches: int\n",
    "            Number of epoches training should last.\n",
    "        args.multi_output: True\n",
    "            If True, specifies that the model is multi-output.\n",
    "            If False, specifies that the model is not multi-output.\n",
    "            Affects the loss function used in model training.\n",
    "        args.evaluate_every: int\n",
    "            Number of epoches that must occur before recording a training/validation accuracy for recordkeeping.\n",
    "        args.ckpt_path: str\n",
    "            Location to record model training checkpoints.\n",
    "    model: torch.nn.Module\n",
    "        Model to train.\n",
    "    optimizer: Optimizers in torch.optim\n",
    "        Optimizer to use in training.\n",
    "    loss_fn: PyTorch Loss Function class object\n",
    "        PyTorch cost function to use in model training.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set number of epochs for training.\n",
    "    EPOCH = args.epoches\n",
    "    \n",
    "    # Generate dataloaders.\n",
    "    train_dataloader, valid_dataloader, test_dataloader = get_dataloaders(args, \n",
    "                                                                          PARTICLES, \n",
    "                                                                          PARTICLES,\n",
    "                                                                          test_diff_particle=False)\n",
    "    \n",
    "    # Step counter.\n",
    "    step = 0\n",
    "\n",
    "    # Initialize lists and dictionaries to use to store loss and accuracy.\n",
    "    # These are used for plotting the loss and accuracy of the model during the training process.\n",
    "    train_loss_values = []\n",
    "    train_accuracies = {\n",
    "        'Total': [],\n",
    "        'Count': [],\n",
    "        'Particle': []\n",
    "    }\n",
    "    valid_loss_values = []\n",
    "    valid_accuracies = {\n",
    "        'Total': [],\n",
    "        'Count': [],\n",
    "        'Particle': []\n",
    "    }\n",
    "    \n",
    "    # Training loop.\n",
    "    for epoch in range(EPOCH):\n",
    "        epoch_train_loss = 0.0\n",
    "        with tqdm(total=len(train_dataloader)) as t: \n",
    "            for i, (inputs, count_labels, particle_labels) in enumerate(train_dataloader):\n",
    "                \n",
    "                # Train model.\n",
    "                step += 1\n",
    "                model.train()\n",
    "\n",
    "                # Send inputs to device.\n",
    "                inputs = inputs.to(device)\n",
    "                \n",
    "                # Calculate the loss.\n",
    "                if not args.multi_output:\n",
    "                    outputs = model(inputs)\n",
    "                    loss = loss_fn(outputs, count_labels.squeeze(0).to(device))\n",
    "                else:\n",
    "                    y1, y2 = model(inputs)\n",
    "                    loss1 = loss_fn(y1, count_labels.squeeze(0).to(device))\n",
    "                    loss2 = loss_fn(y2, particle_labels.squeeze(0).to(device))\n",
    "                    loss = 4 * loss1 + loss2\n",
    "                \n",
    "                # Use optimizer to see where model weights should be changed.\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "\n",
    "                # Get the loss.\n",
    "                cost = loss.item()\n",
    "                \n",
    "                epoch_train_loss = cost\n",
    "                \n",
    "                t.set_postfix(train_loss='{:05.3f}'.format(cost))\n",
    "                t.update()\n",
    "                \n",
    "                # torch.cuda.empty_cache()\n",
    "        \n",
    "        # Print out accuracy and loss metrics if condition is met.\n",
    "        if epoch % args.evaluate_every == 0:\n",
    "            valid_accuracy, valid_count_accuracy, valid_particle_accuracy, valid_loss = evaluate(model, criterion, valid_dataloader)\n",
    "            valid_accuracies['Total'].append(valid_accuracy)\n",
    "            valid_accuracies['Count'].append(valid_count_accuracy)\n",
    "            valid_accuracies['Particle'].append(valid_particle_accuracy)\n",
    "            valid_loss_values.append(valid_loss)\n",
    "            \n",
    "            train_accuracy, train_count_accuracy, train_particle_accuracy, train_loss = evaluate(model, criterion, train_dataloader)\n",
    "            train_accuracies['Total'].append(train_accuracy)\n",
    "            train_accuracies['Count'].append(train_count_accuracy)\n",
    "            train_accuracies['Particle'].append(train_particle_accuracy)\n",
    "            train_loss_values.append(train_loss)\n",
    "            \n",
    "            print(f'Step {step}: valid loss={valid_loss}, \\n valid accuracy={valid_accuracy}, \\n valid count accuracy={valid_count_accuracy}, \\n valid particle accuracy={valid_particle_accuracy}')\n",
    "            print(f'Step {step}: train loss={train_loss}, \\n train accuracy={train_accuracy}, \\n train count accuracy={train_count_accuracy}, \\n valid particle accuracy={train_particle_accuracy}')\n",
    "\n",
    "    # Save the model in designated checkpoint path.\n",
    "    torch.save(model.state_dict(), args.ckpt_path)\n",
    "    \n",
    "    # Plot the accuracy and loss of train/validation sets.\n",
    "    plot_loss(args, train_loss_values, 'train')\n",
    "    plot_accuracies(args, train_accuracies, 'train')\n",
    "    plot_loss(args, valid_loss_values, 'validation')\n",
    "    plot_accuracies(args, valid_accuracies, 'validation')\n",
    "    \n",
    "    # Retrieve and display test set accuracy.\n",
    "    test_accuracy, test_count_accuracy, test_particle_accuracy, _ = evaluate(model, criterion, test_dataloader)\n",
    "    print('Test accuracy: %f' % test_accuracy)\n",
    "    print('Test count accuracy: %f' % test_count_accuracy)\n",
    "    print('Test particle accuracy: %f' % test_particle_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(args, accuracies, split):\n",
    "    \"\"\"\n",
    "    Creates and displays a matplotlib plot representing the accuracy of the model at each epoch.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args:\n",
    "        args.logdir: str\n",
    "            Directory location to save an image of the plots.\n",
    "        args.model: str\n",
    "            ID representing the model that has been trained.\n",
    "    accuracies: dict(list(float))\n",
    "        Dictionary of list of floats representing accuracy values recorded during training; contains overall, particle, and count accuracy values.\n",
    "    split: str\n",
    "        String representing the type of dataset that the accuracy values represent; ex. \"train\" or \"validation\"\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.title(f\"Total, count, and particle accuracies for {split} set\")\n",
    "    plt.plot(accuracies['Total'], label=\"Total\", color='r')\n",
    "    plt.plot(accuracies['Count'], label=\"Count\", color='g')\n",
    "    plt.plot(accuracies['Particle'], label=\"Particle\", color='b')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{args.logdir}/{args.model}_{split}_accuracies_{dt.now()}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(args, loss_values, split):\n",
    "    \"\"\"\n",
    "    Creates and displays a matplotlib plot representing the loss at each epoch during model training.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args:\n",
    "        args.logdir: str\n",
    "            Directory location to save an image of the plots.\n",
    "        args.model: str\n",
    "            ID representing the model that has been trained.\n",
    "    loss_values: list(float)\n",
    "        List of floats representing the loss the model experienced at each epoch.\n",
    "    split: str\n",
    "        String representing the type of dataset that the accuracy values represent; ex. \"train\" or \"validation\"\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.title(f\"{split} loss\")\n",
    "    plt.plot(loss_values,label=\"train\", color='b')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{args.logdir}/{args.model}_{split}_loss_{dt.now()}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8KR3TXppwp_"
   },
   "source": [
    "# Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(args):\n",
    "    \"\"\"\n",
    "    Loads the model for model training.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args:\n",
    "        args.model: str\n",
    "            The model to load. Must be one of the following:\n",
    "            {multi_output_cnn_3_layers, multi_output_cnn_5_layers,\n",
    "             multi_output_cnn_10_layers, multi_output_cnn_18_layers,\n",
    "             multi_output_cnn_early, multi_output_resnet18, multi_output_vgg16}\n",
    "        args.num_particles: int\n",
    "            Number of unique particles to have model train on.\n",
    "        args.num_counts: int\n",
    "            Number of unique count types to have model train on.\n",
    "    \"\"\"\n",
    "    if args.model == 'multi_output_cnn_3_layers':\n",
    "        num_particles = args.num_particles\n",
    "        num_counts = args.num_counts\n",
    "        hidden_dim = 8\n",
    "        model = MultiOutputCNN_3Layer(num_particles=num_particles, num_counts=num_counts, hidden_dim=hidden_dim).to(device)\n",
    "    elif args.model == 'multi_output_cnn_5_layers':\n",
    "        num_particles = args.num_particles\n",
    "        num_counts = args.num_counts\n",
    "        hidden_dim = 8\n",
    "        model = MultiOutputCNN_5Layer(num_particles=num_particles, num_counts=num_counts, hidden_dim=hidden_dim).to(device)\n",
    "    elif args.model == 'multi_output_cnn_10_layers':\n",
    "        num_particles = args.num_particles\n",
    "        num_counts = args.num_counts\n",
    "        hidden_dim = 8\n",
    "        model = MultiOutputCNN_10Layer(num_particles=num_particles, num_counts=num_counts, hidden_dim=hidden_dim).to(device)\n",
    "    elif args.model == 'multi_output_cnn_18_layers':\n",
    "        num_particles = args.num_particles\n",
    "        num_counts = args.num_counts\n",
    "        hidden_dim = 8\n",
    "        model = MultiOutputCNN_18Layer(num_particles=num_particles, num_counts=num_counts, hidden_dim=hidden_dim).to(device)\n",
    "    elif args.model == 'multi_output_cnn_early':\n",
    "        num_particles = args.num_particles\n",
    "        num_counts = args.num_counts\n",
    "        hidden_dim = 8\n",
    "        model = MultiOutputCNN_Early(num_particles=num_particles, num_counts=num_counts, hidden_dim=hidden_dim).to(device)\n",
    "    elif args.model == 'multi_output_resnet18':\n",
    "        num_particles = args.num_particles\n",
    "        num_counts = args.num_counts\n",
    "        model = CustomResNet18Model(num_counts, num_particles).to(device)\n",
    "    elif args.model == 'multi_output_vgg16':\n",
    "        num_particles = args.num_particles\n",
    "        num_counts = args.num_counts\n",
    "        model = CustomVgg16Model(num_counts, num_particles).to(device)\n",
    "    else:\n",
    "        raise Exception('Invalid model type specified. Please selected from following: {multi_output_cnn_3_layers, multi_output_cnn_5_layers, multi_output_cnn_10_layers, multi_output_cnn_18_layers, multi_output_cnn_early, multi_output_resnet18, multi_output_vgg16}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1621182656734,
     "user": {
      "displayName": "Enci Liu",
      "photoUrl": "",
      "userId": "13274077478020183171"
     },
     "user_tz": 420
    },
    "id": "aY0fb-Sipdp2"
   },
   "outputs": [],
   "source": [
    "# Particles to train model on.\n",
    "PARTICLES = ['1fpv', '1ss8', '3j03', '1ijg', '3iyf', '6ody', '6sp2', '6xs6', '7dwz', '7dx8', '7dx9']\n",
    "\n",
    "# Particle counts to train model on.\n",
    "COUNTS = ['single', 'double', 'triple', 'quadruple']\n",
    "\n",
    "LENGTH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1621182690734,
     "user": {
      "displayName": "Enci Liu",
      "photoUrl": "",
      "userId": "13274077478020183171"
     },
     "user_tz": 420
    },
    "id": "dfjn88C4pYk4"
   },
   "outputs": [],
   "source": [
    "# 'model': Specify the model you want to train.\n",
    "# 'root_dir': Directory containing the training data.\n",
    "# 'epoches': Number of epoches to train model on.\n",
    "# 'batch_size': Size of image batch for training.\n",
    "# 'shuffle': If True, shuffle image datasets.\n",
    "# 'num_workers': Number of subprocesses to use for data loading.\n",
    "# 'num_particles': Number of particles in PARTICLES list.\n",
    "# 'num_counts': Number of count types in COUNTS list.\n",
    "# 'length': Same as LENGTH.\n",
    "# 'evaluate_every': Number of epoches between every recording of accuracy and loss values.\n",
    "# 'logdir': Directory to store log information about model training.\n",
    "# 'multi-output': If True, specifies that the model is multi-output.\n",
    "args = {\n",
    "    'model': 'multi_output_cnn_3_layers',\n",
    "    'root_dir': 'PATH TO DATA',\n",
    "    'epoches': 20,\n",
    "    'batch_size': 128,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 1,\n",
    "    'num_particles': 11,\n",
    "    'num_counts': 4,\n",
    "    'length': LENGTH,\n",
    "    'evaluate_every': 1,\n",
    "    'logdir': './logs',\n",
    "    'multi_output': True\n",
    "}\n",
    "\n",
    "args = Namespace(**args)\n",
    "args.ckpt_path = f'{args.logdir}/{args.model}_checkpoint.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1621182693181,
     "user": {
      "displayName": "Enci Liu",
      "photoUrl": "",
      "userId": "13274077478020183171"
     },
     "user_tz": 420
    },
    "id": "HYHvT8q5-eKd"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define loss function and optimizer\n",
    "\n",
    "We will use the cross entropy loss and Adam optimizer\n",
    "\"\"\"\n",
    "\n",
    "# Create model\n",
    "model = load_model(args)\n",
    "\n",
    "# Define the cost function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer, learning rate \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(args, model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw confusion matrix for particle prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, test_dataloader = get_dataloaders(args, PARTICLES, PARTICLES, test_diff_particle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "nb_classes = 11\n",
    "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
    "\n",
    "for i, (inputs, count_labels, particle_labels) in enumerate(test_dataloader):\n",
    "    inputs = inputs.to(device)\n",
    "    _, y2 = model(inputs)\n",
    "    y2 = torch.argmax(y2, dim=-1).to('cpu').numpy().tolist()\n",
    "    for t, p in zip(particle_labels, y2):\n",
    "        confusion_matrix[t, p] += 1\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "class_names = list(particle2idx.keys())\n",
    "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
    "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=12)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=12)\n",
    "plt.ylabel('True label', fontsize=15)\n",
    "plt.xlabel('Predicted label', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 22717,
     "status": "ok",
     "timestamp": 1621182717152,
     "user": {
      "displayName": "Enci Liu",
      "photoUrl": "",
      "userId": "13274077478020183171"
     },
     "user_tz": 420
    },
    "id": "5PbSgdRfkpMG",
    "outputId": "b7978379-c6f9-4e28-b613-4c212493369e"
   },
   "outputs": [],
   "source": [
    "summary(model, input_size=(1, 128, 128))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "pipeline.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
