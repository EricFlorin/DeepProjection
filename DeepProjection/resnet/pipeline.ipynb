{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs from the [following paper](http://cs230.stanford.edu/projects_spring_2021/reports/54.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import socket\n",
    "print(socket.gethostname())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2076,
     "status": "ok",
     "timestamp": 1621182233169,
     "user": {
      "displayName": "Enci Liu",
      "photoUrl": "",
      "userId": "13274077478020183171"
     },
     "user_tz": 420
    },
    "id": "ocNRQsIznK8n",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import argparse\n",
    "from argparse import Namespace\n",
    "\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorboard\n",
    "# from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from resnet import resnet18, resnet34, resnet50\n",
    "from datetime import datetime as dt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7gi1BCstuFv"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle2idx = {\n",
    "    '1fpv': 0,\n",
    "    '1ss8': 1,\n",
    "    '3j03': 2,\n",
    "    '1ijg': 3,\n",
    "    '3iyf': 4,\n",
    "    '6ody': 5,\n",
    "    '6sp2': 6,\n",
    "    '6xs6': 7,\n",
    "    '7dwz': 8,\n",
    "    '7dx8': 9,\n",
    "    '7dx9': 10\n",
    "}\n",
    "\n",
    "count2idx = {\n",
    "    'single': 0,\n",
    "    'double': 1,\n",
    "    'triple': 2,\n",
    "    'quadruple': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2particle = {\n",
    "    0: '1fpv',\n",
    "    2: '1ss8',\n",
    "    2: '3j03',\n",
    "    3: '1ijg',\n",
    "    4: '3iyf',\n",
    "    5: '6ody',\n",
    "    6: '6sp2',\n",
    "    7: '6xs6',\n",
    "    8: '7dwz',\n",
    "    9: '7dx8',\n",
    "    10: '7dx9'\n",
    "}\n",
    "\n",
    "idx2count = {\n",
    "    0: 'single',\n",
    "    1: 'double',\n",
    "    2: 'triple',\n",
    "    3: 'quadruple'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, particles, counts, transform=None, seed=1234):\n",
    "        \"\"\"\n",
    "        CustomDataset is used to contain diffraction images used in model training.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        root_dir: str\n",
    "            String representing the directory path of the diffraction image datasets.\n",
    "        particles: list(str)\n",
    "            List of strings representing the PDB IDs of the particles being used for model training.\n",
    "        counts: list(str)\n",
    "            List of strings representing the particle count of the images being used for model training.\n",
    "        transform: torchvision.transforms.Compose\n",
    "            A torchvision.transforms.Compose object containing the transforms to apply to the diffraction images.\n",
    "        seed: int\n",
    "            An integer used to seed the randomization of the order of the data.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.count_labels = []\n",
    "        self.particle_labels = []\n",
    "        self.data = []\n",
    "\n",
    "        for particle in particles:\n",
    "            for count in counts:\n",
    "                \n",
    "                # Create directory path to dataset\n",
    "                \n",
    "                ##### Uncomment for datasets created by Shawn Cai\n",
    "                if count == 'single':\n",
    "                    n = 4\n",
    "                else:\n",
    "                    n = 1\n",
    "                data_dir = f'{self.root_dir}/SPI_{particle}_{str(n)}k_{count}_thumbnail.h5'\n",
    "                \n",
    "                ##### Uncomment for datasets created by Eric Florin\n",
    "                #n = 5    # Used in generating the file names of files to open; n = 5 will open up 5k image datasets\n",
    "                #data_dir = f'{self.root_dir}/{particle}_{str(n)}k_{count}_pps_1e14_thumbnail.h5'\n",
    "\n",
    "                # Load images as h5 files\n",
    "                f = h5py.File(data_dir, 'r')\n",
    "                dset_name = list(f.keys())[0]\n",
    "                data = f[dset_name]\n",
    "                data = [Image.fromarray(data[i]) for i in range(LENGTH * n)]   # Converts data into PIL images.\n",
    "                \n",
    "                # DEBUG\n",
    "                # Display 20 of the original images\n",
    "                #print('Original shape: ' + str(data[0].size))\n",
    "                #fig = plt.figure(figsize=(15, 15))\n",
    "                #fig.suptitle('Original', y=0.91, fontsize=16)\n",
    "                #columns = 4\n",
    "                #rows = 5\n",
    "                #for i in range(1, columns * rows + 1):\n",
    "                #    img = np.array(data[i - 1])\n",
    "                #    fig.add_subplot(rows, columns, i)\n",
    "                #    plt.imshow(img, vmin=0, vmax=25)\n",
    "                #    plt.colorbar()\n",
    "                #plt.show()\n",
    "                \n",
    "                # Apply transforms to images\n",
    "                data = [self.transform(data[i]) for i in range(LENGTH * n)]\n",
    "                \n",
    "                # DEBUG\n",
    "                # Display 20 of the transformed images\n",
    "                #print('Transformed shape: ' + str(data[0].shape))\n",
    "                #fig = plt.figure(figsize=(15, 15))\n",
    "                #fig.suptitle('Transformed From Original', y=0.91, fontsize=16)\n",
    "                #columns = 4\n",
    "                #rows = 5\n",
    "                #for i in range(1, columns * rows + 1):\n",
    "                #    img = data[i - 1].numpy()\n",
    "                #    img = np.squeeze(img)\n",
    "                #    fig.add_subplot(rows, columns, i)\n",
    "                #    plt.imshow(img, vmin=0, vmax=25)\n",
    "                #    plt.colorbar()\n",
    "                #plt.show()\n",
    "                \n",
    "                # Apply image labels\n",
    "                count_label = [count2idx[count]] * (LENGTH * n)\n",
    "                particle_label = [particle2idx[particle]] * (LENGTH * n)\n",
    "                self.data.extend(data)\n",
    "                self.count_labels.extend(count_label)\n",
    "                self.particle_labels.extend(particle_label)\n",
    "        \n",
    "        # Shuffle the data\n",
    "        random.seed(seed)\n",
    "        perm = list(range(len(self.data)))\n",
    "        random.shuffle(perm)\n",
    "        self.data = [self.data[i] for i in perm]\n",
    "        self.count_labels = [self.count_labels[i] for i in perm]\n",
    "        self.particle_labels = [self.particle_labels[i] for i in perm]\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Denotes the total number of samples'''\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Generates one sample of data'''\n",
    "        X = self.data[index]\n",
    "        count = self.count_labels[index]\n",
    "        particle = self.particle_labels[index]\n",
    "        return X, count, particle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AddNoise Class: A wrapper for the addNoise() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNoise(object):\n",
    "    \"\"\"\n",
    "    A wrapper for addNoise(), so that it can be used with other torch transform functions.\n",
    "    AddNoise applies the following noise to images:\n",
    "        1. Reduce the fluence by a factor of 100.\n",
    "        2. Add poisson noise.\n",
    "        3. Add gaussian noise given a sigma value.\n",
    "        4. Varience normalization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, flux_jitter, gaussian_noise):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        flux_jitter: float\n",
    "            Flux jitter to use when reducing the fluence of the image.\n",
    "            \n",
    "        gaussian_noise: float\n",
    "            Alias for sigma to be used in gaussian distribution. Sets how much\n",
    "            gaussian noise to apply to image.\n",
    "        \"\"\"\n",
    "        assert isinstance(flux_jitter, float)\n",
    "        assert isinstance(gaussian_noise, float)\n",
    "        self.flux_jitter = flux_jitter\n",
    "        self.gaussian_noise = gaussian_noise\n",
    "\n",
    "    def __call__(self, image):\n",
    "        \"\"\" Called by PyTorch when applying the AddNoise transform. \"\"\"\n",
    "        return self.addNoise(image)\n",
    "\n",
    "    def addNoise(self, orig_img):\n",
    "        \"\"\"\n",
    "        Applies the following noise to a given image:\n",
    "            1. Reduce the fluence by a factor of 100.\n",
    "            2. Add poisson noise.\n",
    "            3. Add gaussian noise given a sigma value.\n",
    "            4. Varience normalization.\n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        orig_img: PIL Image\n",
    "            Image to apply noise to.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        PIL Image\n",
    "            Image with noise applied to it.\n",
    "        \"\"\"\n",
    "        \n",
    "        def changeIntensity(img, flux_jitter):\n",
    "            factor = 100 # Reduces the fluence of the image by a factor of 100. Ex. 1e14 photons/pulse -> 1e12 photons/pulse.\n",
    "            mu = 1 # mean jitter\n",
    "            alpha = np.random.normal(mu, flux_jitter)\n",
    "            if alpha <= 0: alpha = 0.1 # alpha can't be zero\n",
    "            n_photons = alpha*np.sum(img) / factor                     # number of desired photons per image\n",
    "            return n_photons*(img/np.sum(img)) # cache noise-free measurement\n",
    "    \n",
    "        def poisson(img):\n",
    "            # add poisson noise\n",
    "            return np.random.poisson(img)      # apply Poisson statistics\n",
    "    \n",
    "        def gaussian(img, sigma):\n",
    "            # add gaussian noise \n",
    "            # For random samples from N(\\mu, \\sigma^2), \n",
    "            # mu + sigma * np.random.randn(...)\n",
    "            # sigma: Gaussian noise level\n",
    "            img = img + sigma*np.random.randn(*img.shape);  # apply Gaussian statistics\n",
    "            return img\n",
    "    \n",
    "        def varNorm(V):\n",
    "            # variance normalization, each image has mean 0, variance 1\n",
    "            # This shouldn't happen, but zero out infinite pixels\n",
    "            V[np.argwhere(V==np.inf)] = 0\n",
    "            mean = np.mean(V)\n",
    "            std = np.std(V)\n",
    "            if std == 0:\n",
    "                return np.zeros_like(V)\n",
    "            V1 = (V-mean)/std\n",
    "            return V1\n",
    "\n",
    "        def transform(img):\n",
    "            img = changeIntensity(img, self.flux_jitter)\n",
    "            img = poisson(img)\n",
    "            img = gaussian(img, self.gaussian_noise)\n",
    "            img = varNorm(img)\n",
    "            return img\n",
    "        \n",
    "        return Image.fromarray(transform(orig_img))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1621182238687,
     "user": {
      "displayName": "Enci Liu",
      "photoUrl": "",
      "userId": "13274077478020183171"
     },
     "user_tz": 420
    },
    "id": "d_-YQ56vVwhn"
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(args, train_val_particles, test_particles, test_diff_particle=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates torch.utils.data.DataLoader objects for the training, validation, and testing. Part of this includes applying augmentations and noise to the diffraction images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    args\n",
    "        args.num_particles: int\n",
    "            Number of unique particles in train_val_particles and test_particles.\n",
    "        args.root_dir: str\n",
    "            String representation of directory containing the data needed for training/testing.\n",
    "        args.batch_size: int\n",
    "            Batch size for DataLoaders.\n",
    "        args.shuffle: bool\n",
    "            Shuffle the data in DataLoaders.\n",
    "        args.num_workers: int\n",
    "            Number of subprocesses to use for data loading.\n",
    "    \n",
    "    train_val_particles: list(str)\n",
    "        List of str representing the PDB IDs of particles used for training and validation sets.\n",
    "\n",
    "    test_particles: list(str) \n",
    "        List of str representing the PDB IDs of particles used for test sets.\n",
    "\n",
    "    test_diff_particle: bool\n",
    "        If True, create a test dataloader that uses a different set of particles not specified in train_val_particles or test_particles.\n",
    "        If False, create a test dataloader that uses the same set of particles specified in train_val_particles/test_particles; train_val_particles and test_particles must be the same!\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    A training DataLoader, a validation DataLoader, and a test DataLoader.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Original from Shawn\n",
    "    transform = transforms.Compose([transforms.CenterCrop(128),\n",
    "                                    transforms.RandomVerticalFlip(p=0.5),\n",
    "                                    transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                    transforms.ToTensor()])\n",
    "    data_len = args.num_particles * 7000      # For Shawn's original dataset; num_particles * (4k single images + 1k double images + 1k triple images + 1k quadruple images)\n",
    "    \n",
    "    \n",
    "    # Eric Florin's Version\n",
    "    # Removed transforms.CenterCrop(128) because it was zooming in on the images during the crop.\n",
    "    # Added transforms.RandomAffine() to add rotation and zoom transforms.\n",
    "    # Added AddNoise(), a custom PyTorch transform to wrap the addNoise() function.\n",
    "    #transform = transforms.Compose([transforms.RandomVerticalFlip(p=0.5),\n",
    "    #                                transforms.RandomHorizontalFlip(p=0.5),\n",
    "    #                                transforms.RandomAffine(degrees=360, scale=(0.9, 1.1)),\n",
    "    #                                AddNoise(0.9, 0.15),\n",
    "    #                                transforms.ToTensor()])\n",
    "    #data_len = args.num_particles * 20000        # For EricFlorin's dataset; num_particles * (5k single images + 5k double images + 5k triple images + 5k quadruple images)\n",
    "    \n",
    "    if not test_diff_particle:\n",
    "        assert train_val_particles == test_particles\n",
    "        dataset = CustomDataset(root_dir=args.root_dir,\n",
    "                                particles=train_val_particles,\n",
    "                                counts=COUNTS,\n",
    "                                transform=transform)\n",
    "        print(len(dataset))\n",
    "        train_idx = list(range(0, int(data_len * 0.7)))\n",
    "        valid_idx = list(range(int(data_len * 0.7), int(data_len * 0.8)))\n",
    "        test_idx = list(range(int(data_len * 0.8), data_len))\n",
    "        train_dataset = Subset(dataset, train_idx) \n",
    "        valid_dataset = Subset(dataset, valid_idx)\n",
    "        test_dataset = Subset(dataset, test_idx)\n",
    "    else:\n",
    "        # Create train/valid/test datasets\n",
    "        train_val_dataset = CustomDataset(root_dir=args.root_dir, \n",
    "                                          particles=train_val_particles,\n",
    "                                          counts=COUNTS,\n",
    "                                          transform=transform)\n",
    "        train_idx = list(range(0, 7000))\n",
    "        valid_idx = list(range(7000, 8000))\n",
    "        train_dataset = Subset(train_val_dataset, train_idx) \n",
    "        valid_dataset = Subset(train_val_dataset, valid_idx)\n",
    "        test_dataset = CustomDataset(root_dir=args.root_dir, \n",
    "                                    particles=test_particles,\n",
    "                                    counts=COUNTS,\n",
    "                                    transform=transform)\n",
    "        \n",
    "        assert train_dataset.__getitem__(0)[0].shape == torch.Size([1, 128, 128])\n",
    "        assert valid_dataset.__getitem__(0)[0].shape == torch.Size([1, 128, 128])\n",
    "        assert test_dataset.__getitem__(0)[0].shape == torch.Size([1, 128, 128])\n",
    "\n",
    "    # Create train/valid/test dataloaders\n",
    "    train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  shuffle=args.shuffle, \n",
    "                                  num_workers=args.num_workers)\n",
    "    valid_dataloader = DataLoader(dataset=valid_dataset,\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  shuffle=args.shuffle, \n",
    "                                  num_workers=args.num_workers)\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, \n",
    "                                 batch_size=args.batch_size, \n",
    "                                 shuffle=args.shuffle, \n",
    "                                 num_workers=args.num_workers)\n",
    "    return train_dataloader, valid_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bF6OxCUL9r3n"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-layer Multi-output CNN (Late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputCNN(nn.Module):\n",
    "    def __init__(self, num_particles=11, num_counts=4, hidden_dim=8):\n",
    "        super(MultiOutputCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, hidden_dim, 2, 2) # (8, 64, 64)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim * 4, 4, 4) # (32, 16, 16)\n",
    "        self.conv3 = nn.Conv2d(hidden_dim * 4, hidden_dim * 16, 4, 4) # (128, 4, 4)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(2048, num_counts)\n",
    "        self.fc2 = nn.Linear(2048, num_particles)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        y1 = self.fc1(x)\n",
    "        y1 = F.log_softmax(y1, dim=1)\n",
    "        y2 = self.fc2(x)\n",
    "        y2 = F.log_softmax(y2, dim=1)\n",
    "        return y1, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-layer Multi-output CNN (Late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputCNN(nn.Module):\n",
    "    def __init__(self, num_particles=11, num_counts=4, hidden_dim=8):\n",
    "        super(MultiOutputCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, hidden_dim, 2, 2) # (8, 64, 64)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim * 2, 2, 2) # (16, 32, 32)\n",
    "        self.conv3 = nn.Conv2d(hidden_dim * 2, hidden_dim * 4, 2, 2) # (32, 16, 16)\n",
    "        self.conv4 = nn.Conv2d(hidden_dim * 4, hidden_dim * 8, 2, 2) # (64, 8, 8)\n",
    "        self.conv5 = nn.Conv2d(hidden_dim * 8, hidden_dim * 16, 2, 2) # (128, 4, 4)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(2048, num_counts)\n",
    "        self.fc2 = nn.Linear(2048, num_particles)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        y1 = self.fc1(x)\n",
    "        y1 = F.log_softmax(y1, dim=1)\n",
    "        y2 = self.fc2(x)\n",
    "        y2 = F.log_softmax(y2, dim=1)\n",
    "        return y1, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-layer Multi-output CNN (Late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputCNN(nn.Module):\n",
    "    def __init__(self, num_particles=11, num_counts=4, hidden_dim=8):\n",
    "        super(MultiOutputCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, hidden_dim, 2, 2) # (8, 64, 64)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim * 2, 2, 2) # (16, 32, 32)\n",
    "        self.conv3 = nn.Conv2d(hidden_dim * 2, hidden_dim * 4, 2, 2) # (32, 16, 16)\n",
    "        self.conv4 = nn.Conv2d(hidden_dim * 4, hidden_dim * 8, 2, 2) # (64, 8, 8)\n",
    "        self.conv5 = nn.Conv2d(hidden_dim * 8, hidden_dim * 8, 2, 1) # (64, 7, 7)\n",
    "        self.conv6 = nn.Conv2d(hidden_dim * 8, hidden_dim * 8, 2, 1) # (64, 6, 6)\n",
    "        self.conv7 = nn.Conv2d(hidden_dim * 8, hidden_dim * 8, 2, 1) # (64, 5, 5)\n",
    "        self.conv8 = nn.Conv2d(hidden_dim * 8, hidden_dim * 16, 1, 1) # (128, 5, 5)\n",
    "        self.conv9 = nn.Conv2d(hidden_dim * 16, hidden_dim * 16, 2, 1) # (128, 4, 4)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(2048, num_counts)\n",
    "        self.fc2 = nn.Linear(2048, num_particles)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv7(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv8(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv9(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        y1 = self.fc1(x)\n",
    "        y1 = F.log_softmax(y1, dim=1)\n",
    "        y2 = self.fc2(x)\n",
    "        y2 = F.log_softmax(y2, dim=1)\n",
    "        return y1, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18-layer Multi-output CNN (Late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputCNN(nn.Module):\n",
    "    def __init__(self, num_particles=11, num_counts=4, hidden_dim=8):\n",
    "        super(MultiOutputCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, hidden_dim, 2, 2) # (8, 64, 64)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim * 2, 2, 2) # (16, 32, 32)\n",
    "        self.conv3 = nn.Conv2d(hidden_dim * 2, hidden_dim * 4, 2, 2) # (32, 16, 16)\n",
    "        self.conv4 = nn.Conv2d(hidden_dim * 4, hidden_dim * 4, 2, 1) # (32, 15, 15)\n",
    "        self.conv5 = nn.Conv2d(hidden_dim * 4, hidden_dim * 4, 2, 1) # (32, 14, 14)\n",
    "        self.conv6 = nn.Conv2d(hidden_dim * 4, hidden_dim * 4, 2, 1) # (32, 13, 13)\n",
    "        self.conv7 = nn.Conv2d(hidden_dim * 4, hidden_dim * 4, 2, 1) # (32, 12, 12)\n",
    "        self.conv8 = nn.Conv2d(hidden_dim * 4, hidden_dim * 4, 2, 1) # (32, 11, 11)\n",
    "        self.conv9 = nn.Conv2d(hidden_dim * 4, hidden_dim * 4, 2, 1) # (32, 10, 10)\n",
    "        self.conv10 = nn.Conv2d(hidden_dim * 4, hidden_dim * 4, 2, 1) # (32, 9, 9)\n",
    "        self.conv11 = nn.Conv2d(hidden_dim * 4, hidden_dim * 8, 1, 1) # (64, 9, 9)\n",
    "        self.conv12 = nn.Conv2d(hidden_dim * 8, hidden_dim * 8, 2, 1) # (64, 8, 8)\n",
    "        self.conv13 = nn.Conv2d(hidden_dim * 8, hidden_dim * 8, 2, 1) # (64, 7, 7)\n",
    "        self.conv14 = nn.Conv2d(hidden_dim * 8, hidden_dim * 8, 2, 1) # (64, 6, 6)\n",
    "        self.conv15 = nn.Conv2d(hidden_dim * 8, hidden_dim * 8, 2, 1) # (64, 5, 5)\n",
    "        self.conv16 = nn.Conv2d(hidden_dim * 8, hidden_dim * 16, 1, 1) # (128, 5, 5)\n",
    "        self.conv17 = nn.Conv2d(hidden_dim * 16, hidden_dim * 16, 2, 1) # (128, 4, 4)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(2048, num_counts)\n",
    "        self.fc2 = nn.Linear(2048, num_particles)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv7(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv8(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv9(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv10(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv11(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv12(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv13(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv14(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv15(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv16(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv17(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        y1 = self.fc1(x)\n",
    "        y1 = F.log_softmax(y1, dim=1)\n",
    "        y2 = self.fc2(x)\n",
    "        y2 = F.log_softmax(y2, dim=1)\n",
    "        return y1, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-output CNN (Early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputCNN(nn.Module):\n",
    "    def __init__(self, num_particles=11, num_counts=4, hidden_dim=8):\n",
    "        super(MultiOutputCNN, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, hidden_dim, 2, 2) # (8, 64, 64)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim * 2, 2, 2) # (16, 32, 32)\n",
    "        \n",
    "        #Branched\n",
    "        self.conv3_b1 = nn.Conv2d(hidden_dim * 2, hidden_dim * 4, 2, 2) # (32, 16, 16)\n",
    "        self.conv4_b1 = nn.Conv2d(hidden_dim * 4, hidden_dim * 8, 2, 2) # (64, 8, 8)\n",
    "        self.conv5_b1 = nn.Conv2d(hidden_dim * 8, hidden_dim * 8, 2, 1) # (64, 7, 7)\n",
    "        self.conv6_b1 = nn.Conv2d(hidden_dim * 8, hidden_dim * 8, 2, 1) # (64, 6, 6)\n",
    "        self.conv7_b1 = nn.Conv2d(hidden_dim * 8, hidden_dim * 8, 2, 1) # (64, 5, 5)\n",
    "        self.conv8_b1 = nn.Conv2d(hidden_dim * 8, hidden_dim * 16, 1, 1) # (128, 5, 5)\n",
    "        self.conv9_b1 = nn.Conv2d(hidden_dim * 16, hidden_dim * 16, 2, 1) # (128, 4, 4)\n",
    "        self.dropout1_b1 = nn.Dropout(0.25)\n",
    "        self.fc1_b1 = nn.Linear(2048, num_counts)\n",
    "        \n",
    "        self.conv3_b2 = nn.Conv2d(hidden_dim * 2, hidden_dim * 4, 2, 2) # (32, 16, 16)\n",
    "        self.conv4_b2 = nn.Conv2d(hidden_dim * 4, hidden_dim * 8, 2, 2) # (64, 8, 8)\n",
    "        self.conv5_b2 = nn.Conv2d(hidden_dim * 8, hidden_dim * 8, 2, 1) # (64, 7, 7)\n",
    "        self.conv6_b2 = nn.Conv2d(hidden_dim * 8, hidden_dim * 8, 2, 1) # (64, 6, 6)\n",
    "        self.conv7_b2 = nn.Conv2d(hidden_dim * 8, hidden_dim * 8, 2, 1) # (64, 5, 5)\n",
    "        self.conv8_b2 = nn.Conv2d(hidden_dim * 8, hidden_dim * 16, 1, 1) # (128, 5, 5)\n",
    "        self.conv9_b2 = nn.Conv2d(hidden_dim * 16, hidden_dim * 16, 2, 1) # (128, 4, 4)\n",
    "        self.dropout1_b2 = nn.Dropout(0.25)\n",
    "        self.fc1_b2 = nn.Linear(2048, num_particles)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #Branched\n",
    "        y1 = self.conv3_b1(x)\n",
    "        y1 = F.relu(y1)\n",
    "        y1 = self.conv4_b1(y1)\n",
    "        y1 = F.relu(y1)\n",
    "        y1 = self.conv5_b1(y1)\n",
    "        y1 = F.relu(y1)\n",
    "        y1 = self.conv6_b1(y1)\n",
    "        y1 = F.relu(y1)\n",
    "        y1 = self.conv7_b1(y1)\n",
    "        y1 = F.relu(y1)\n",
    "        y1 = self.conv8_b1(y1)\n",
    "        y1 = F.relu(y1)\n",
    "        y1 = self.conv9_b1(y1)\n",
    "        y1 = F.relu(y1)\n",
    "        y1 = self.dropout1_b1(y1)\n",
    "        y1 = torch.flatten(y1, 1)\n",
    "        y1 = self.fc1_b1(y1)\n",
    "        y1 = F.log_softmax(y1, dim=1)\n",
    "\n",
    "        y2 = self.conv3_b2(x)\n",
    "        y2 = F.relu(y2)\n",
    "        y2 = self.conv4_b2(y2)\n",
    "        y2 = F.relu(y2)\n",
    "        y2 = self.conv5_b2(y2)\n",
    "        y2 = F.relu(y2)\n",
    "        y2 = self.conv6_b2(y2)\n",
    "        y2 = F.relu(y2)\n",
    "        y2 = self.conv7_b2(y2)\n",
    "        y2 = F.relu(y2)\n",
    "        y2 = self.conv8_b2(y2)\n",
    "        y2 = F.relu(y2)\n",
    "        y2 = self.conv9_b2(y2)\n",
    "        y2 = F.relu(y2)\n",
    "        y2 = self.dropout1_b2(y2)\n",
    "        y2 = torch.flatten(y2, 1)\n",
    "        y2 = self.fc1_b2(y2)\n",
    "        y2 = F.log_softmax(y2, dim=1)\n",
    "\n",
    "        return y1, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomResNet18Model(nn.Module):\n",
    "    def __init__(self, num_counts, num_particles):\n",
    "        super(CustomResNet18Model, self).__init__()\n",
    "        self.model_resnet = models.resnet18(pretrained=False)\n",
    "        self.model_resnet.conv1 = torch.nn.Conv1d(1, 64, (7, 7), (2, 2), (3, 3), bias=True)\n",
    "        \n",
    "        self.model_resnet.fc.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.5, training=m.training))\n",
    "        \n",
    "        num_ftrs = self.model_resnet.fc.in_features\n",
    "        self.model_resnet.fc = nn.Identity()\n",
    "        self.fc1 = nn.Linear(num_ftrs, num_counts)\n",
    "        self.fc2 = nn.Linear(num_ftrs, num_particles)\n",
    "    def forward(self, x):\n",
    "        x = self.model_resnet(x)\n",
    "        out1 = self.fc1(x)\n",
    "        y1 = F.log_softmax(out1, dim=1)\n",
    "        out2 = self.fc2(x)\n",
    "        y2 = F.log_softmax(out2, dim=1)\n",
    "        return y1, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomVgg16Model(nn.Module):\n",
    "    def __init__(self, num_counts, num_particles):\n",
    "        super(CustomVgg16Model, self).__init__()\n",
    "        self.model_vgg16 = models.vgg16(pretrained=False, progress=True)\n",
    "        self.model_vgg16.features[0] = torch.nn.Conv2d(1, 64, (3, 3), (1, 1), (1, 1))\n",
    "        num_ftrs = self.model_vgg16.classifier[0].in_features\n",
    "        self.model_vgg16.classifier = nn.Identity()\n",
    "        self.fc1 = nn.Linear(num_ftrs, num_counts)\n",
    "        self.fc2 = nn.Linear(num_ftrs, num_particles)\n",
    "    def forward(self, x):\n",
    "        x = self.model_vgg16(x)\n",
    "        out1 = self.fc1(x)\n",
    "        y1 = F.log_softmax(out1, dim=1)\n",
    "        out2 = self.fc2(x)\n",
    "        y2 = F.log_softmax(out2, dim=1)\n",
    "        return y1, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xNRaiMqZUt5"
   },
   "source": [
    "# Evalutate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1621182654483,
     "user": {
      "displayName": "Enci Liu",
      "photoUrl": "",
      "userId": "13274077478020183171"
     },
     "user_tz": 420
    },
    "id": "90SAviZnS3vz"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, dataloader):\n",
    "    \"\"\"Evaluate the model on `num_steps` batches.\n",
    "    Args:\n",
    "        model: (torch.nn.Module) the neural network\n",
    "        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
    "        dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches data\n",
    "        \n",
    "    Return:\n",
    "        accuracy: float\n",
    "            Overall accuracy of the model.\n",
    "        count_accuracy: float\n",
    "            Accuracy of model in identifying whether an image is single-hit or multi-hit (ex. double, triple, quadruple).\n",
    "        particle_accuracy: float\n",
    "            Accuracy of model in identifying the particle from diffraction images.\n",
    "        loss: float\n",
    "            Loss of the model a training step.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    accuracies = []\n",
    "    loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    preds1 = []\n",
    "    preds2 = []\n",
    "    all_count_labels = []\n",
    "    all_particle_labels = []\n",
    "    all_images = []\n",
    "    for i, (inputs, count_labels, particle_labels) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        if not args.multi_output:\n",
    "            outputs = model(inputs)\n",
    "            batch_loss = loss_fn(outputs, count_labels.squeeze(0).to(device))\n",
    "            loss += batch_loss\n",
    "            preds = torch.argmax(outputs, dim=-1)\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(count_labels)\n",
    "            loss = loss / len(dataloader)\n",
    "        else:\n",
    "            y1, y2 = model(inputs)\n",
    "            loss1 = loss_fn(y1, count_labels.squeeze(0).to(device)).detach().item()\n",
    "            loss2 = loss_fn(y2, particle_labels.squeeze(0).to(device)).detach().item()\n",
    "            batch_loss = 4 * loss1 + loss2\n",
    "            loss += batch_loss\n",
    "            y1 = torch.argmax(y1, dim=-1).to('cpu').numpy().tolist()\n",
    "            y2 = torch.argmax(y2, dim=-1).to('cpu').numpy().tolist()\n",
    "            \n",
    "            preds1.extend(y1)\n",
    "            preds2.extend(y2)\n",
    "            all_images.extend(inputs)\n",
    "            all_count_labels.extend(count_labels.to('cpu').numpy().tolist())\n",
    "            all_particle_labels.extend(particle_labels.to('cpu').numpy().tolist())\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Total accuracy\n",
    "    correct_pred = [1 if (preds1[i] == all_count_labels[i] and preds2[i] == all_particle_labels[i]) else 0 for i in range(len(preds1))]\n",
    "    accuracy = sum(correct_pred) / len(preds1) * 100\n",
    "    \n",
    "    # Count accuracy\n",
    "    correct_pred_count = [1 if (preds1[i] == all_count_labels[i]) else 0 for i in range(len(preds1))]\n",
    "    count_accuracy = sum(correct_pred_count) / len(preds1) * 100\n",
    "    \n",
    "    # Particle accuracy\n",
    "    correct_pred_particle = [1 if (preds2[i] == all_particle_labels[i]) else 0 for i in range(len(preds2))]\n",
    "    particle_accuracy = sum(correct_pred_particle) / len(preds1) * 100\n",
    "    \n",
    "    loss = loss / len(dataloader)\n",
    "    \n",
    "    # Compute accuracy for each particle type\n",
    "    particle_acc_dict = {}\n",
    "    for idx in idx2particle:\n",
    "        temp = {}\n",
    "        temp['crct'] = sum([1 if (preds2[i] == idx and preds2[i] == all_particle_labels[i]) else 0 for i in range(len(preds2))])\n",
    "        temp['total'] = sum([1 if (all_particle_labels[i] == idx) else 0 for i in range(len(all_particle_labels))])\n",
    "        particle_acc_dict[idx2particle[idx]] = temp['crct'] / temp['total']\n",
    "        if idx2particle[idx] == '7dx8':\n",
    "            wrong_pred_7dx8 = [preds2[i] if (all_particle_labels[i] == idx and preds2[i] != all_particle_labels[i]) else None for i in range(len(preds2))]\n",
    "    print(particle_acc_dict)\n",
    "\n",
    "    return accuracy, count_accuracy, particle_accuracy, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1n0r3qXAtzEx"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 579,
     "status": "ok",
     "timestamp": 1621182655834,
     "user": {
      "displayName": "Enci Liu",
      "photoUrl": "",
      "userId": "13274077478020183171"
     },
     "user_tz": 420
    },
    "id": "18sO4iAot0bH"
   },
   "outputs": [],
   "source": [
    "def train(args, model, optimizer, loss_fn):\n",
    "    \"\"\"\n",
    "    Train the network on the training data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args\n",
    "        args.epoches: int\n",
    "            Number of epoches training should last.\n",
    "        args.multi_output: True\n",
    "            If True, specifies that the model is multi-output.\n",
    "            If False, specifies that the model is not multi-output.\n",
    "            Affects the loss function used in model training.\n",
    "        args.evaluate_every: int\n",
    "            Number of epoches that must occur before recording a training/validation accuracy for recordkeeping.\n",
    "        args.ckpt_path: str\n",
    "            Location to record model training checkpoints.\n",
    "    model: torch.nn.Module\n",
    "        Model to train.\n",
    "    optimizer: Optimizers in torch.optim\n",
    "        Optimizer to use in training.\n",
    "    loss_fn: PyTorch Loss Function class object\n",
    "        PyTorch cost function to use in model training.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set number of epochs for training.\n",
    "    EPOCH = args.epoches\n",
    "    \n",
    "    # Generate dataloaders.\n",
    "    train_dataloader, valid_dataloader, test_dataloader = get_dataloaders(args, \n",
    "                                                                          PARTICLES, \n",
    "                                                                          PARTICLES,\n",
    "                                                                          test_diff_particle=False)\n",
    "    # Step counter.\n",
    "    step = 0\n",
    "\n",
    "    # Initialize lists and dictionaries to use to store loss and accuracy.\n",
    "    # These are used for plotting the loss and accuracy of the model during the training process.\n",
    "    train_loss_values = []\n",
    "    train_accuracies = {\n",
    "        'Total': [],\n",
    "        'Count': [],\n",
    "        'Particle': []\n",
    "    }\n",
    "    valid_loss_values = []\n",
    "    valid_accuracies = {\n",
    "        'Total': [],\n",
    "        'Count': [],\n",
    "        'Particle': []\n",
    "    }\n",
    "    \n",
    "    # Training loop.\n",
    "    for epoch in range(EPOCH):\n",
    "        epoch_train_loss = 0.0\n",
    "        with tqdm(total=len(train_dataloader)) as t: \n",
    "            for i, (inputs, count_labels, particle_labels) in enumerate(train_dataloader):\n",
    "                \n",
    "                # Train model.\n",
    "                step += 1\n",
    "                model.train()\n",
    "\n",
    "                # Send inputs to device.\n",
    "                inputs = inputs.to(device)\n",
    "                \n",
    "                # Calculate the loss.\n",
    "                if not args.multi_output:\n",
    "                    outputs = model(inputs)\n",
    "                    loss = loss_fn(outputs, count_labels.squeeze(0).to(device))\n",
    "                else:\n",
    "                    y1, y2 = model(inputs)\n",
    "                    loss1 = loss_fn(y1, count_labels.squeeze(0).to(device))\n",
    "                    loss2 = loss_fn(y2, particle_labels.squeeze(0).to(device))\n",
    "                    loss = 4 * loss1 + loss2\n",
    "                \n",
    "                # Use optimizer to see where model weights should be changed.\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "\n",
    "                # Get the loss.\n",
    "                cost = loss.item()\n",
    "                \n",
    "                epoch_train_loss = cost\n",
    "                \n",
    "                t.set_postfix(train_loss='{:05.3f}'.format(cost))\n",
    "                t.update()\n",
    "                \n",
    "                # torch.cuda.empty_cache()\n",
    "        \n",
    "        # Print out accuracy and loss metrics if condition is met.\n",
    "        if epoch % args.evaluate_every == 0:\n",
    "            valid_accuracy, valid_count_accuracy, valid_particle_accuracy, valid_loss = evaluate(model, criterion, valid_dataloader)\n",
    "            valid_accuracies['Total'].append(valid_accuracy)\n",
    "            valid_accuracies['Count'].append(valid_count_accuracy)\n",
    "            valid_accuracies['Particle'].append(valid_particle_accuracy)\n",
    "            valid_loss_values.append(valid_loss)\n",
    "            \n",
    "            train_accuracy, train_count_accuracy, train_particle_accuracy, train_loss = evaluate(model, criterion, train_dataloader)\n",
    "            train_accuracies['Total'].append(train_accuracy)\n",
    "            train_accuracies['Count'].append(train_count_accuracy)\n",
    "            train_accuracies['Particle'].append(train_particle_accuracy)\n",
    "            train_loss_values.append(train_loss)\n",
    "            \n",
    "            print(f'Step {step}: valid loss={valid_loss}, \\n valid accuracy={valid_accuracy}, \\n valid count accuracy={valid_count_accuracy}, \\n valid particle accuracy={valid_particle_accuracy}')\n",
    "            print(f'Step {step}: train loss={train_loss}, \\n train accuracy={train_accuracy}, \\n train count accuracy={train_count_accuracy}, \\n valid particle accuracy={train_particle_accuracy}')\n",
    "\n",
    "    # Save the model in designated checkpoint path.\n",
    "    torch.save(model.state_dict(), args.ckpt_path)\n",
    "    \n",
    "    # Plot the accuracy and loss of train/validation sets.\n",
    "    plot_loss(args, train_loss_values, 'train')\n",
    "    plot_accuracies(args, train_accuracies, 'train')\n",
    "    plot_loss(args, valid_loss_values, 'validation')\n",
    "    plot_accuracies(args, valid_accuracies, 'validation')\n",
    "    \n",
    "    # Retrieve and display test set accuracy.\n",
    "    test_accuracy, test_count_accuracy, test_particle_accuracy, _ = evaluate(model, criterion, test_dataloader)\n",
    "    print('Test accuracy: %f' % test_accuracy)\n",
    "    print('Test count accuracy: %f' % test_count_accuracy)\n",
    "    print('Test particle accuracy: %f' % test_particle_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(args, accuracies, split):\n",
    "    \"\"\"\n",
    "    Creates and displays a matplotlib plot representing the accuracy of the model at each epoch.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args:\n",
    "        args.logdir: str\n",
    "            Directory location to save an image of the plots.\n",
    "        args.model: str\n",
    "            ID representing the model that has been trained.\n",
    "    accuracies: dict(list(float))\n",
    "        Dictionary of list of floats representing accuracy values recorded during training; contains overall, particle, and count accuracy values.\n",
    "    split: str\n",
    "        String representing the type of dataset that the accuracy values represent; ex. \"train\" or \"validation\"\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.title(f\"Total, count, and particle accuracies for {split} set\")\n",
    "    plt.plot(accuracies['Total'], label=\"Total\", color='r')\n",
    "    plt.plot(accuracies['Count'], label=\"Count\", color='g')\n",
    "    plt.plot(accuracies['Particle'], label=\"Particle\", color='b')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{args.logdir}/{args.model}_{split}_accuracies_{dt.now()}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(args, loss_values, split):\n",
    "    \"\"\"\n",
    "    Creates and displays a matplotlib plot representing the loss at each epoch during model training.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args:\n",
    "        args.logdir: str\n",
    "            Directory location to save an image of the plots.\n",
    "        args.model: str\n",
    "            ID representing the model that has been trained.\n",
    "    loss_values: list(float)\n",
    "        List of floats representing the loss the model experienced at each epoch.\n",
    "    split: str\n",
    "        String representing the type of dataset that the accuracy values represent; ex. \"train\" or \"validation\"\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.title(f\"{split} loss\")\n",
    "    plt.plot(loss_values,label=\"train\", color='b')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{args.logdir}/{args.model}_{split}_loss_{dt.now()}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8KR3TXppwp_"
   },
   "source": [
    "# Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(args):\n",
    "    \"\"\"\n",
    "    Loads the model for model training.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args:\n",
    "        args.model: str\n",
    "            The model to load. Must be one of the following: {multi_output_cnn, multi_output_resnet18, multi_output_vgg16}\n",
    "        args.num_particles: int\n",
    "            Number of unique particles to have model train on.\n",
    "        args.num_counts: int\n",
    "            Number of unique count types to have model train on.\n",
    "    \"\"\"\n",
    "    \n",
    "    if args.model == 'multi_output_cnn':\n",
    "        num_particles = args.num_particles\n",
    "        num_counts = args.num_counts\n",
    "        hidden_dim = 8\n",
    "        model = MultiOutputCNN(num_particles=num_particles, num_counts=num_counts, hidden_dim=hidden_dim).to(device)\n",
    "    elif args.model == 'multi_output_resnet18':\n",
    "        num_particles = args.num_particles\n",
    "        num_counts = args.num_counts\n",
    "        model = CustomResNet18Model(num_counts, num_particles).to(device)\n",
    "    elif args.model == 'multi_output_vgg16':\n",
    "        num_particles = args.num_particles\n",
    "        num_counts = args.num_counts\n",
    "        model = CustomVgg16Model(num_counts, num_particles).to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1621182656734,
     "user": {
      "displayName": "Enci Liu",
      "photoUrl": "",
      "userId": "13274077478020183171"
     },
     "user_tz": 420
    },
    "id": "aY0fb-Sipdp2"
   },
   "outputs": [],
   "source": [
    "# Particles to train model on.\n",
    "PARTICLES = ['1fpv', '1ss8', '3j03', '1ijg', '3iyf', '6ody', '6sp2', '6xs6', '7dwz', '7dx8', '7dx9']\n",
    "\n",
    "# Particle counts to train model on.\n",
    "COUNTS = ['single', 'double', 'triple', 'quadruple']\n",
    "\n",
    "# Multiple of the number of images in each dataset.\n",
    "# Ex. If you have datasets containing 5000 images, then LENGTH = 5000 / 5 = 1000\n",
    "LENGTH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1621182690734,
     "user": {
      "displayName": "Enci Liu",
      "photoUrl": "",
      "userId": "13274077478020183171"
     },
     "user_tz": 420
    },
    "id": "dfjn88C4pYk4"
   },
   "outputs": [],
   "source": [
    "# 'model': Specify the model you want to train.\n",
    "# 'root_dir': Directory containing the training data.\n",
    "# 'epoches': Number of epoches to train model on.\n",
    "# 'batch_size': Size of image batch for training.\n",
    "# 'shuffle': If True, shuffle image datasets.\n",
    "# 'num_workers': Number of subprocesses to use for data loading.\n",
    "# 'num_particles': Number of particles in PARTICLES list.\n",
    "# 'num_counts': Number of count types in COUNTS list.\n",
    "# 'length': Same as LENGTH.\n",
    "# 'evaluate_every': Number of epoches between every recording of accuracy and loss values.\n",
    "# 'logdir': Directory to store log information about model training.\n",
    "# 'multi-output': If True, specifies that the model is multi-output.\n",
    "args = {\n",
    "    'model': 'multi_output_cnn', # multi_output_cnn || multi_output_resnet18 || multi_output_vgg16\n",
    "    'root_dir': '/sdf/home/x/xericfl/scratch/eric_data',\n",
    "    'epoches': 20,\n",
    "    'batch_size': 128,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 1,\n",
    "    'num_particles': 11,\n",
    "    'num_counts': 4,\n",
    "    'length': LENGTH,\n",
    "    'evaluate_every': 1,\n",
    "    'logdir': './logs',\n",
    "    'multi_output': True\n",
    "}\n",
    "\n",
    "args = Namespace(**args)\n",
    "args.ckpt_path = f'{args.logdir}/{args.model}_checkpoint.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1621182693181,
     "user": {
      "displayName": "Enci Liu",
      "photoUrl": "",
      "userId": "13274077478020183171"
     },
     "user_tz": 420
    },
    "id": "HYHvT8q5-eKd"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define loss function and optimizer\n",
    "\n",
    "We will use the cross entropy loss and Adam optimizer\n",
    "\"\"\"\n",
    "\n",
    "# Create model\n",
    "model = load_model(args)\n",
    "\n",
    "# Define the cost function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer, learning rate \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(args, model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw confusion matrix for particle prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, test_dataloader = get_dataloaders(args, PARTICLES, PARTICLES, test_diff_particle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "nb_classes = 11\n",
    "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
    "\n",
    "for i, (inputs, count_labels, particle_labels) in enumerate(test_dataloader):\n",
    "    inputs = inputs.to(device)\n",
    "    _, y2 = model(inputs)\n",
    "    y2 = torch.argmax(y2, dim=-1).to('cpu').numpy().tolist()\n",
    "    for t, p in zip(particle_labels, y2):\n",
    "        confusion_matrix[t, p] += 1\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "class_names = list(particle2idx.keys())\n",
    "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
    "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=12)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=12)\n",
    "plt.ylabel('True label', fontsize=15)\n",
    "plt.xlabel('Predicted label', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 22717,
     "status": "ok",
     "timestamp": 1621182717152,
     "user": {
      "displayName": "Enci Liu",
      "photoUrl": "",
      "userId": "13274077478020183171"
     },
     "user_tz": 420
    },
    "id": "5PbSgdRfkpMG",
    "outputId": "b7978379-c6f9-4e28-b613-4c212493369e"
   },
   "outputs": [],
   "source": [
    "summary(model, input_size=(1, 128, 128))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "pipeline.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
